{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from argparse import Namespace\n",
    "\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import nibabel as nib\n",
    "\n",
    "from scipy import signal\n",
    "from torchmetrics import MeanSquaredError\n",
    "from viu.io import volume\n",
    "from viu.torch.deformation.fields import DVF\n",
    "from viu.torch.math import torch_affine_to_vol_mat\n",
    "from viu.util.body_mask import seg_body\n",
    "\n",
    "from pamomo.registration.deformable import reg\n",
    "import torch\n",
    "import torch.nn.functional as tt\n",
    "\n",
    "from exampleUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(src='/home/wd974888/Downloads/workingFolder/DeformationExperiment/readFormat/Patient09PB_bin_01.nii.gz', dst='/home/wd974888/Downloads/workingFolder/DeformationExperiment/readFormat/Patient09PB_bin_11.nii.gz', body_seg=True, air_threshold=-300, alpha=50, verboseMode=False, maxNumberOfIterations=100, numLevels=3, saveMovedAsNIIFlag=True)\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\\\n",
    "    src=f'/home/wd974888/Downloads/workingFolder/DeformationExperiment/readFormat/Patient09PB_bin_01.nii.gz',\\\n",
    "    dst=f'/home/wd974888/Downloads/workingFolder/DeformationExperiment/readFormat/Patient09PB_bin_11.nii.gz',\\\n",
    "    body_seg=True,\\\n",
    "    air_threshold=-300,\\\n",
    "    alpha=50,\\\n",
    "    verboseMode=False,\\\n",
    "    maxNumberOfIterations=100,\\\n",
    "    numLevels=3,\\\n",
    "    saveMovedAsNIIFlag=True)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "runFreshRegistration=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_vol dtype float64,  shape ZYX (590, 512, 512), res XYZ [0.9765625 0.9765625 1.       ], pos XYZ [-249.50999451 -469.51000977 -352.3999939 ]\n",
      "dst_vol dtype float64,  shape ZYX (590, 512, 512), res XYZ [0.9765625 0.9765625 1.       ], pos XYZ [-249.50999451 -469.51000977 -352.3999939 ]\n",
      "B4 DVFify dvf type <class 'numpy.ndarray'>  dtype float32,  shape ZYX (295, 256, 256, 3)\n",
      "B4 tensorify dvf_res dtype float64,  shape (3,), value XYZ  [1.95695466 1.95695466 2.00340136]\n",
      "B4 tensorify dvf_pos dtype float64,  shape (3,), value XYZ  [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#registrationCommand(args)\n",
    "dst_path = os.path.dirname(args.dst)\n",
    "\n",
    "src_vol: np.ndarray\n",
    "if args.src.endswith('.nii.gz') and args.dst.endswith('.nii.gz'):\n",
    "    src_vol, src_res, src_pos = ImportFromNII(args.src)\n",
    "    dst_vol, dst_res, dst_pos = ImportFromNII(args.dst)\n",
    "else:\n",
    "    src_vol, src_res, src_pos = volume.read_volume(args.src)\n",
    "    dst_vol, dst_res, dst_pos = volume.read_volume(args.dst)\n",
    "\n",
    "print(f'src_vol dtype {src_vol.dtype},  shape ZYX {src_vol.shape}, res XYZ {src_res}, pos XYZ {src_pos}')\n",
    "# src_vol dtype float64,  shape ZYX (590, 512, 512), res XYZ [0.9765625 0.9765625 1.       ], pos XYZ [-249.50999451 -469.51000977 -352.3999939 ]\n",
    "print(f'dst_vol dtype {dst_vol.dtype},  shape ZYX {dst_vol.shape}, res XYZ {dst_res}, pos XYZ {dst_pos}')\n",
    "# dst_vol dtype float64,  shape ZYX (590, 512, 512), res XYZ [0.9765625 0.9765625 1.       ], pos XYZ [-249.50999451 -469.51000977 -352.3999939 ]\n",
    "\n",
    "cachedPath = os.path.join(dst_path, f'Patient09PB_cachedDVF.npz')\n",
    "if True==runFreshRegistration:\n",
    "\n",
    "    additional_args = {}\n",
    "    if args.body_seg:\n",
    "        print('Find connected components...')\n",
    "        #Find connected components...\n",
    "        msk = seg_body(dst_vol, air_threshold=args.air_threshold)\n",
    "        additional_args.update({'dst_seg': {'SM_bodymask': msk}, 'similarityMaskMultilevelStrategy': 'STRICTINTERIOR'})\n",
    "\n",
    "    print('Start registration...')\n",
    "    vol_min = -1200\n",
    "    dvf, dvf_res, dvf_pos = reg(src_vol.clip(min=vol_min), src_res,\n",
    "                                dst_vol.clip(min=vol_min), dst_res,\n",
    "                                alpha=args.alpha,#alpha=20,\n",
    "                                numLevels=args.numLevels,\n",
    "                                # finestLevelReference=0,\n",
    "                                # finestLevelTemplate=0,\n",
    "                                maxNumberOfIterations=args.maxNumberOfIterations,\n",
    "                                **additional_args) #verboseMode=args.verboseMode, **additional_args #verboseMode='true', **additional_args\n",
    "    np.savez_compressed(cachedPath, dvf, dvf_res, dvf_pos)\n",
    "    # Start registration...\n",
    "\n",
    "    # This is the Fraunhofer MEVIS cuda registration library. Version: VarianDeformableRegistrationDLLCUDA -- v1.6.2, built Dec 11 2023, 20:49:53\n",
    "    # numSourceSegments <= 0. Running without mask alignment. Continuing.\n",
    "    # Started registration...\n",
    "    # Optimization on level 1 / 3 needs: 3.39014 s\n",
    "    # Optimization on level 2 / 3 needs: 8.03293 s\n",
    "    # Optimization on level 3 / 3 needs: 84.1789 s\n",
    "    # Finished multilevel registration.\n",
    "    # Total runtime: 103.207s.\n",
    "    # Done.\n",
    "else:\n",
    "    cachedDVF = np.load(cachedPath)\n",
    "    dvf, dvf_res, dvf_pos = cachedDVF['arr_0'], cachedDVF['arr_1'], cachedDVF['arr_2']\n",
    "\n",
    "print(f'B4 DVFify dvf type {type(dvf)}  dtype {dvf.dtype},  shape ZYX {dvf.shape}')\n",
    "# B4 DVFify dvf type <class 'numpy.ndarray'>  dtype float32,  shape ZYX (295, 256, 256, 3)\n",
    "print(f'B4 tensorify dvf_res dtype {dvf_res.dtype},  shape {dvf_res.shape}, value XYZ  {dvf_res}')\n",
    "# B4 tensorify dvf_res dtype float64,  shape (3,), value XYZ  [1.95695466 1.95695466 2.00340136]\n",
    "print(f'B4 tensorify dvf_pos dtype {dvf_pos.dtype},  shape {dvf_pos.shape}, value XYZ  {dvf_pos}')\n",
    "# B4 tensorify dvf_pos dtype float64,  shape (3,), value XYZ  [0. 0. 0.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After tensorify dvf_res dtype torch.float64,  shape torch.Size([3]), value XYZ  tensor([1.9570, 1.9570, 2.0034], dtype=torch.float64)\n",
      "After tensorify dvf_pos dtype torch.float64,  shape torch.Size([3]), value XYZ  tensor([0., 0., 0.], dtype=torch.float64)\n",
      "dst_dim in XYZ dtype torch.int64,  shape torch.Size([3]), value XYZ  tensor([512, 512, 590])\n",
      "dst_res in XYZ dtype torch.float64,  shape torch.Size([3]), value XYZ  tensor([0.9766, 0.9766, 1.0000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "dvf_res = torch.tensor(dvf_res, dtype=torch.float64)\n",
    "print(f'After tensorify dvf_res dtype {dvf_res.dtype},  shape {dvf_res.shape}, value XYZ  {dvf_res}')\n",
    "dvf_pos = torch.tensor(dvf_pos, dtype=torch.float64)\n",
    "print(f'After tensorify dvf_pos dtype {dvf_pos.dtype},  shape {dvf_pos.shape}, value XYZ  {dvf_pos}')\n",
    "\n",
    "dst_dim = torch.tensor(dst_vol.shape[::-1]) #From ZYX to XYZ\n",
    "print(f'dst_dim in XYZ dtype {dst_dim.dtype},  shape {dst_dim.shape}, value XYZ  {dst_dim}')\n",
    "dst_res = torch.tensor(dst_res, dtype=torch.float64)\n",
    "print(f'dst_res in XYZ dtype {dst_res.dtype},  shape {dst_res.shape}, value XYZ  {dst_res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched_dvf DVF object   dtype torch.float32,  shape ZYX3 torch.Size([1, 295, 256, 256, 3])\n"
     ]
    }
   ],
   "source": [
    "#Create unbatched DVF object\n",
    "# dvf = DVF(dvf).from_millimeter(dvf_res).to(torch.float32)\n",
    "# Above line gives error: DVFs can be formed only of tensors of shape (B,H,W,2) or (B,D,H,W,3). Provided shape: torch.Size([295, 256, 256, 3]).\n",
    "batched_dvf = DVF(dvf[None,...]).from_millimeter(dvf_res).to(torch.float32)\n",
    "print(f'batched_dvf DVF object   dtype {batched_dvf.dtype},  shape ZYX3 {batched_dvf.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Old resample of unbatched DVF\n",
    "# dvf = dvf.resample(\n",
    "#     dst_dim,\n",
    "#     dst_res,\n",
    "#     #dst_pos: torch.Tensor = torch.zeros(3, dtype=torch.float64), <--- default\n",
    "#     dvf_res=dvf_res,\n",
    "#     dvf_pos=dvf_pos\n",
    "#     # mode=\"bilinear\",\n",
    "#     # padding_mode=\"border\"\n",
    "#     )\n",
    "# print(f'Resampled dvf type: {type(dvf)}')\n",
    "# ######## Exception happening  otherwise ######\n",
    "# if dvf.dtype !=torch.tensor(src_vol).dtype:\n",
    "#     #Making both float32\n",
    "#     # dvf = dvf.to(torch.tensor(src_vol).dtype)\n",
    "#     dvf = dvf.to(torch.float32)\n",
    "#     src_vol = src_vol.astype('float32')\n",
    "# #########################################\n",
    "# print(f'Resampled DVF object   dtype {dvf.dtype},  shape ZYX3 {dvf.shape}')\n",
    "# #With change in sample() we need to have batch dimension added to DVF and batch and channel  dimension added to  input\n",
    "# batched_dvf = dvf.unsqueeze(0)\n",
    "# print(f'batched_dvf  object   dtype {batched_dvf.dtype},  shape ZYX3 {batched_dvf.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled DVF object  type <class 'viu.torch.deformation.fields.DVF'>   dtype torch.float32,  shape ZYX3 torch.Size([1, 590, 512, 512, 3])\n"
     ]
    }
   ],
   "source": [
    "# Resample of batched DVF without preFilter\n",
    "batched_dvf1 = batched_dvf.resample(\n",
    "    dst_dim,\n",
    "    dst_res,\n",
    "    #dst_pos: torch.Tensor = torch.zeros(3, dtype=torch.float64), <--- default\n",
    "    dvf_res=dvf_res,\n",
    "    dvf_pos=dvf_pos,\n",
    "    mode=\"bilinear\",\n",
    "    padding_mode=\"border\",\n",
    "    prefilter=False\n",
    "    )\n",
    "if batched_dvf1.dtype !=torch.tensor(src_vol).dtype:\n",
    "    #Making both float32\n",
    "    batched_dvf1 = batched_dvf1.to(torch.float32)\n",
    "    src_vol = src_vol.astype('float32')\n",
    "print(f'Resampled DVF object  type {type(batched_dvf1)}   dtype {batched_dvf1.dtype},  shape ZYX3 {batched_dvf1.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Any\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from viu.torch.math import torch_affine_to_vol_mat, st_mat_ex\n",
    "# from .utils import permute_input, permute_output, ensure_dimensions\n",
    "import os, sys\n",
    "import interpol\n",
    "\n",
    "def resample_try(self_dvf,\n",
    "    dst_dim: torch.Tensor,\n",
    "    dst_res: torch.Tensor,\n",
    "    dst_pos: torch.Tensor = torch.zeros(3, dtype=torch.float64),\n",
    "    dvf_res: torch.Tensor = None,\n",
    "    dvf_pos: torch.Tensor = torch.zeros(3, dtype=torch.float64),\n",
    "    mode=\"bilinear\",\n",
    "    padding_mode=\"border\",\n",
    "    prefilter=False,\n",
    "    attempt = 'attempt3'): # # 'attempt1', 'attempt2', 'attempt3' #NOTE , align_corners=True\n",
    "    \"\"\"\n",
    "    NOTE to self: Parameters dst_dim, dst_pos, dvf_res, dvf_pos are all specified  in XYZ order\n",
    "    while the actual DVF is in ZYX order\n",
    "    \"\"\"\n",
    "    #NOTE hardcoded behaviour\n",
    "    align_corners=True\n",
    "    field_shape = self_dvf.shape\n",
    "    assert  ((4==len(field_shape) and 2==field_shape[-1] ) or (5==len(field_shape) and 3==field_shape[-1] ) ),\\\n",
    "            f'Expected field.shape == (B,H,W,2) or (B,D,H,W,3). Provied field.shape {field_shape}.'\n",
    "    if dvf_res is None:\n",
    "        print(f'Warning DVF resolution not given;  assuming 1.')\n",
    "        dvf_res = torch.ones(len(dst_dim), dtype=torch.float64)\n",
    "    if 4==len(field_shape):\n",
    "        assert (2==len(dst_dim) and 2==len(dst_res) and 2==len(dst_pos) and 2==len(dvf_res) and 2==len(dvf_pos)),\\\n",
    "            f'If 4==len(self.shape) all of dst_dim, dst_res, dst_pos, and original dvf_res, dvf_pos should be 2-element tensor.\\\n",
    "                Provided values: dst_dim {dst_dim} dst_res {dst_res} dst_pos {dst_pos} dvf_res {dvf_res} dvf_pos {dvf_pos}'\n",
    "        nb_dim=2\n",
    "    if 5==len(field_shape):\n",
    "        assert (3==len(dst_dim) and 3==len(dst_res) and 3==len(dst_pos) and 3==len(dvf_res) and 3==len(dvf_pos)),\\\n",
    "            f'If 5==len(self.shape) all of dst_dim, dst_res, dst_pos, and original dvf_res, dvf_pos should be 3-element tensor.\\\n",
    "                Provided values: dst_dim {dst_dim} dst_res {dst_res} dst_pos {dst_pos} dvf_res {dvf_res} dvf_pos {dvf_pos}'\n",
    "        nb_dim=3\n",
    "    # print(f'nb_dim {nb_dim}')\n",
    "\n",
    "    assert prefilter in [True, False], f'prefilter should be a boolean True or False. Passed value : {prefilter}.'\n",
    "    if (False==prefilter):\n",
    "        behaviour=\"torch_Functional\"\n",
    "        assert mode in ['nearest', 'bilinear', 'bicubic'],f'In torch_Functional library, mode should be one of nearest, bilinear, bicubic. Passed value: {mode}'\n",
    "    else:\n",
    "            behaviour=\"torch_interpol\"\n",
    "            assert mode in ['nearest', 'linear', 'quadratic', 'cubic'],f'With prefilter=True, using torch_interpol library and  mode should be one of nearest, linear, quadratic, cubic. Passed value: {mode}'\n",
    "\n",
    "    dvf = self_dvf\n",
    "    batch_Size=self_dvf.shape[0] #We expect batch dimension to be present.\n",
    "    dvf_dim = torch.tensor(self_dvf.shape[1:-1][::-1]) #Earlier self.shape[:-1][::-1] was used. But now we expect batch dimension to be present.`\n",
    "    assert nb_dim==len(dst_dim) and nb_dim==len(dvf_dim),\\\n",
    "        f'Expected nb_dim==len(dst_dim)==len(dvf_dim). Provided: nb_dim {nb_dim} len(dst_dim) {len(dst_dim)} len(dvf_dim) {len(dvf_dim)}'\n",
    "\n",
    "    # Current st_mat method in math.py only supports 4x4 homogeneous matrix for 3D dvf. Therefore instead of using torch_affine_to_vol_mat from \n",
    "    # math.py we explicitly support both 3x3 homogeneous matrix for 2D dvf and 4x4  homogeneous matrix for 3D DVF.\n",
    "    # mat_dvf = torch_affine_to_vol_mat(dvf_dim, dvf_res, dvf_pos).to(dvf.device)\n",
    "    # mat_vol = torch_affine_to_vol_mat(dst_dim, dst_res, dst_pos).to(dvf.device)\n",
    "    mat_dvf=st_mat_ex(s=0.5 * dvf_res * (dvf_dim - 1), t=dvf_pos, nb_dim=nb_dim).to(dvf.device)\n",
    "    mat_vol=st_mat_ex(s=0.5 * dst_res * (dst_dim - 1), t=dst_pos, nb_dim=nb_dim).to(dvf.device)\n",
    "    mat = mat_dvf.inverse().matmul(mat_vol) #Create affine matrix using (vol_to_affine(destination)) * (afffine_to_vol(dvf))\n",
    "    # print(f'mat shape {mat.shape}')\n",
    "    assert (2==nb_dim and torch.Size([3, 3])==mat.shape) or (3==nb_dim and torch.Size([4, 4])==mat.shape),\\\n",
    "        f'With nb_dim {nb_dim} expected mat.shape: [{nb_dim+1}, {nb_dim+1}] but found {mat.shape}'\n",
    "    assert (3==nb_dim and torch.Size([4, 4])==mat.shape),\\\n",
    "        f'With nb_dim {nb_dim} expected mat.shape: [{nb_dim+1}, {nb_dim+1}] but found {mat.shape}'\n",
    "\n",
    "    #Currently torch_interpol behaviour can only be supported if re-sample behaviour is a simple resize behaviour.\n",
    "    #This is because #Attempt-1 and Attempt-2 of converting  the torch-functional grid  into torch-interpol grid\n",
    "    # is not giving the intended  result after warping. Therefore if the affine matrix mat is close to identity matrix, \n",
    "    # we will allow torch-interpol resample to continue; otherwise, we will override user's choice of using torch-interpol \n",
    "    # and use the torch functional behaviour.\n",
    "    identityMatTensor=torch.eye(nb_dim+1).to(torch.float64).to(dvf.device)\n",
    "    if \"torch_interpol\"==behaviour and not torch.isclose(mat, identityMatTensor).all():\n",
    "        behaviour= \"torch_Functional\"\n",
    "        if 'nearest' != mode:\n",
    "            mode='bilinear'\n",
    "        prefilter=False\n",
    "\n",
    "\n",
    "    if not torch.isclose(dvf_dim, dst_dim).all() or \\\n",
    "            not torch.isclose(dvf_res, dst_res).all() or \\\n",
    "            not torch.isclose(dvf_pos, dst_pos).all():\n",
    "\n",
    "        vol_grid_shape = [batch_Size, 1] + dst_dim.tolist()[::-1] #Intended grid shape NOTE earlier it was [1, 1] instead of [batch_Size, 1]\n",
    "        if 2==nb_dim:\n",
    "            dvf = dvf.permute(0, 3, 1, 2) #Treat the source dvf as image by permuting dvf values as image channels\n",
    "        if 3==nb_dim:\n",
    "            dvf = dvf.permute(0, 4, 1, 2, 3) #Treat the source dvf as image by permuting dvf values as image channels\n",
    "        # print(f'dvf shape {dvf.shape}')\n",
    "\n",
    "        pyTorchTheta=mat[:nb_dim, :].to(torch.float32)\n",
    "        pyTorchTheta=pyTorchTheta.expand(batch_Size, *pyTorchTheta.shape)\n",
    "        # print(f'pyTorchTheta shape {pyTorchTheta.shape}')\n",
    "        grid = F.affine_grid(pyTorchTheta,size=vol_grid_shape, align_corners=align_corners) #Generate affine grid\n",
    "        # print(f'grid shape {grid.shape}')\n",
    "\n",
    "        if \"torch_Functional\"==behaviour:\n",
    "            out = F.grid_sample(dvf, grid, mode=mode, padding_mode=padding_mode, align_corners=align_corners)\n",
    "\n",
    "        else: #behaviour==\"torch_interpol\"\n",
    "            [des_depth, des_height, des_width] = dst_dim.tolist()[::-1]\n",
    "            [src_depth, src_height, src_width] = dvf_dim.tolist()[::-1]\n",
    "\n",
    "            assert attempt in ['attempt1', 'attempt2', 'attempt3'], 'Undefined attempt.'\n",
    "\n",
    "            if 'attempt1'==attempt:\n",
    "                #####################################\n",
    "                # #Attempt 1 : # Not working when the resampled grid was used for warping - Why??\n",
    "                # mat_interpol = DVF.getUnNormalizedAffineMatTensorInImageCoord(mat,  src_depth, src_height, src_width,  des_depth, des_height, des_width)\n",
    "                pyTorchAffineMatTensorInNormalizedCoord_a2b=mat\n",
    "                depth_a, height_a, width_a = src_depth, src_height, src_width\n",
    "                depth_b, height_b, width_b = des_depth, des_height, des_width\n",
    "\n",
    "                device = pyTorchAffineMatTensorInNormalizedCoord_a2b.device\n",
    "                print(f'pyTorchAffineMatTensorInNormalizedCoord_a2b {pyTorchAffineMatTensorInNormalizedCoord_a2b}')\n",
    "                block3x3Flipped = pyTorchAffineMatTensorInNormalizedCoord_a2b[0:3, 0:3].flip([0,1])\n",
    "                tmpAffineMat=pyTorchAffineMatTensorInNormalizedCoord_a2b.clone()\n",
    "                tmpAffineMat[0:3, 0:3]=block3x3Flipped\n",
    "                print(f'tmpAffineMat {tmpAffineMat}')\n",
    "\n",
    "                T_regular2normalized_a_yx = torch.tensor([[2./(depth_a), 0, 0, -1.],[ 0, 2./(height_a), 0, -1.],[0, 0, 2./(width_a), -1.], [0, 0, 0, 1.]], dtype=torch.float64).to(device)\n",
    "                T_normalized2regular_b_yx = torch.tensor([[2./(depth_b), 0, 0, -1.],[ 0, 2./(height_b), 0, -1.],[0, 0, 2./(width_b), -1.], [0, 0, 0, 1.]], dtype=torch.float64).to(device).inverse()\n",
    "                #Normalize, convert into tensor, use 1st 3 rows.\n",
    "                unNormalizedAffineMatTensorInImageCoord = T_normalized2regular_b_yx.matmul(tmpAffineMat.matmul(T_regular2normalized_a_yx))\n",
    "                mat_interpol=unNormalizedAffineMatTensorInImageCoord\n",
    "\n",
    "                grid_interpol = interpol.api.affine_grid(mat_interpol.to(torch.float32), [des_depth, des_height, des_width]).to(dvf.device)\n",
    "                grid_interpol_batched = grid_interpol.expand(batch_Size, *grid_interpol.shape)\n",
    "                out=interpol.grid_pull(dvf, grid_interpol_batched, interpolation=mode, bound=padding_mode,prefilter=prefilter)\n",
    "                #####################################\n",
    "\n",
    "            if 'attempt2'==attempt:\n",
    "                # #####################################\n",
    "                # #Attempt 2 # Not working when the resampled grid was used for warping - Why??\n",
    "                # grid_ij_batched_deormalized = DVF._convertGrid_functional2interpol(grid, des_depth, des_height, des_width)\n",
    "                functional_grid_batched, depth, height, width = grid, des_depth, des_height, des_width\n",
    "                # printTensor(\"functional_grid_batched\", functional_grid_batched)\n",
    "                batchSize=functional_grid_batched.shape[0]\n",
    "                #xy to ij\n",
    "                field_ij_batched_normalized = torch.flip(functional_grid_batched, [-1])\n",
    "                #deNormalization matrix : With align_corner=True, we will use depth-1, height-1, width-1\n",
    "                deNormalizationMat = torch.linalg.inv(torch.tensor([[2./(depth), 0, 0, -1.],[ 0, 2./(height), 0, -1.],[0, 0, 2./(width), -1.], [0, 0, 0, 1.]],\n",
    "                    dtype=torch.float32, device=functional_grid_batched.device))\n",
    "                nb_dim = deNormalizationMat.shape[-1] - 1\n",
    "                deNormalizationMat_rot = deNormalizationMat[:nb_dim, :nb_dim]\n",
    "                deNormalizationMat_tr = deNormalizationMat[:nb_dim, -1]\n",
    "                #Expand deNormalization matrix by batchSize\n",
    "                deNormalizationMat_rot = deNormalizationMat_rot.expand(batchSize, 1, 1, 1, *deNormalizationMat_rot.shape)\n",
    "                deNormalizationMat_tr =   deNormalizationMat_tr.expand(batchSize, 1, 1, 1, *deNormalizationMat_tr.shape)\n",
    "                # Add dimension (in-place) in the end to support  matmul with normalizationMat_rot.\n",
    "                # Then remove that dimension before adding  with normalizationMat_tr\n",
    "                field_ij_batched_denormalized = torch.matmul(deNormalizationMat_rot, field_ij_batched_normalized.unsqueeze(-1)).squeeze(-1) + deNormalizationMat_tr\n",
    "                grid_ij_batched_deormalized = field_ij_batched_denormalized# return field_ij_batched_denormalized\n",
    "\n",
    "                out=interpol.grid_pull(dvf, grid_ij_batched_deormalized, interpolation=mode, bound=padding_mode,prefilter=prefilter)\n",
    "                ########################################\n",
    "\n",
    "            if 'attempt3'==attempt:\n",
    "                # Attempt 3 : directly using interpol.resize() which does not make use of  dst_res, dst_pos, dvf_res, dvf_pos\n",
    "                out=interpol.resize(\n",
    "                    image=dvf,\n",
    "                    factor=None,\n",
    "                    shape=dst_dim.tolist()[::-1],\n",
    "                    anchor='c' if True==align_corners else 'e',\n",
    "                    interpolation=mode,\n",
    "                    prefilter=True)\n",
    "\n",
    "        #Put DVF values in last channel\n",
    "        if 2==nb_dim:\n",
    "            out = out.permute(0, 2, 3, 1)\n",
    "        if 3==nb_dim:\n",
    "            out = out.permute(0,2,3,4,1)\n",
    "        #NOTE Are we ensuring that the original DVF object's data got resampled with all gradients and other properties maintained?\n",
    "        if not isinstance(out, DVF):\n",
    "            out=DVF(out)\n",
    "    else:\n",
    "        out=self_dvf\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/testVIU/lib/python3.9/site-packages/interpol/autograd.py:287: UserWarning: operator() sees varying value in profiling, ignoring and this should be handled by GUARD logic (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/third_party/nvfuser/csrc/parser.cpp:3820.)\n",
      "  output = spline_coeff_nd(input, *opt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled DVF object  type: <class 'viu.torch.deformation.fields.DVF'> dtypetorch.float32 shape BZYX3 torch.Size([1, 590, 512, 512, 3])\n",
      "batched_dvf1 min DVF(-0.1099) max DVF(0.0270)\n",
      "batched_dvf2 min DVF(-0.1099) max DVF(0.0271)\n",
      "batched_dvf1 - batched_dvf2 min DVF(-0.0001) max DVF(0.0002) mean DVF(2.7087e-08)\n",
      "|batched_dvf1 - batched_dvf2| min DVF(0.) max DVF(0.0002) mean DVF(3.5387e-06)\n"
     ]
    }
   ],
   "source": [
    "#Resample of batched DVF with preFilter\n",
    "localMethod=False\n",
    "if localMethod:\n",
    "    batched_dvf2 = resample_try(batched_dvf, # batched_dvf.resample(\n",
    "        dst_dim,\n",
    "        dst_res,\n",
    "        #dst_pos: torch.Tensor = torch.zeros(3, dtype=torch.float64), <--- default\n",
    "        dvf_res=dvf_res,\n",
    "        dvf_pos=dvf_pos,\n",
    "        mode=\"cubic\",\n",
    "        padding_mode=\"border\",\n",
    "        prefilter=True,\n",
    "        attempt='attempt3' #\n",
    "        )\n",
    "else:\n",
    "    batched_dvf2 = batched_dvf.resample( # batched_dvf.resample(\n",
    "        dst_dim,\n",
    "        dst_res,\n",
    "        #dst_pos: torch.Tensor = torch.zeros(3, dtype=torch.float64), <--- default\n",
    "        dvf_res=dvf_res,\n",
    "        dvf_pos=dvf_pos,\n",
    "        mode=\"cubic\",\n",
    "        padding_mode=\"border\",\n",
    "        prefilter=True\n",
    "        )\n",
    "if batched_dvf2.dtype !=torch.tensor(src_vol).dtype:\n",
    "    #Making both float32\n",
    "    batched_dvf2 = batched_dvf2.to(torch.float32)\n",
    "    src_vol = src_vol.astype('float32')\n",
    "print(f'Resampled DVF object  type: {type(batched_dvf2)} dtype{batched_dvf2.dtype} shape BZYX3 {batched_dvf2.shape}')\n",
    "\n",
    "#Compare\n",
    "print(f'batched_dvf1 min {torch.min(batched_dvf1)} max {torch.max(batched_dvf1)}')\n",
    "print(f'batched_dvf2 min {torch.min(batched_dvf2)} max {torch.max(batched_dvf2)}')\n",
    "print(f'batched_dvf1 - batched_dvf2 min {torch.min(batched_dvf1 - batched_dvf2)} max {torch.max(batched_dvf1 - batched_dvf2)} mean {torch.mean(batched_dvf1 - batched_dvf2)}')\n",
    "print(f'|batched_dvf1 - batched_dvf2| min {torch.min(torch.abs(batched_dvf1 - batched_dvf2))} max {torch.max(torch.abs(batched_dvf1 - batched_dvf2))} mean {torch.mean(torch.abs(batched_dvf1 - batched_dvf2))}')\n",
    "\n",
    "# Ideal output\n",
    "# batched_dvf1 min DVF(-0.1099) max DVF(0.0270)\n",
    "# batched_dvf2 min DVF(-0.1099) max DVF(0.0271)\n",
    "# batched_dvf1 - batched_dvf2 min DVF(-0.0001) max DVF(0.0002) mean DVF(2.7087e-08)\n",
    "# |batched_dvf1 - batched_dvf2| min DVF(0.) max DVF(0.0002) mean DVF(3.5387e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8997abde0b344bbca842c2bbf3c97aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Output(),), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<exampleUtils.v1_volumeComparisonViewer3D at 0x7f28bc3e5bb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_dvf = (batched_dvf1 - batched_dvf2).cpu().numpy()\n",
    "v1_volumeComparisonViewer3D(\n",
    "    listVolumes=[diff_dvf[0,:,:,:,0], diff_dvf[0,:,:,:,1], diff_dvf[0,:,:,:,2]],listLabels=['diff_ch0', 'diff_ch1', 'diff_ch2'],\n",
    "    maxZ0=diff_dvf[0,:,:,:,0].shape[0], maxZ1=diff_dvf[0,:,:,:,0].shape[1], maxZ2=diff_dvf[0,:,:,:,0].shape[2],\n",
    "    figsize=(12,8), cmap='coolwarm',\n",
    "    displayColorbar=True, useExternalWindowCenter=True, wMin=-0.05, wMax=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vol_tensor  object   dtype torch.float32,  shape ZYX3 torch.Size([1, 1, 590, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "vol_tensor = torch.tensor(src_vol).unsqueeze(0).unsqueeze(0)\n",
    "print(f'vol_tensor  object   dtype {vol_tensor.dtype},  shape ZYX3 {vol_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warped_vol_F_noPreFilter  object   dtype float32,  shape ZYX3 (590, 512, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b85e10e37b4ae2be78ac8d10a5d1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Output(),), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<exampleUtils.v1_volumeComparisonViewer3D at 0x7f28bc4742b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#_call_ method => pull warping, no prefilter\n",
    "# warped_vol_F_noPreFilter = batched_dvf1(vol_tensor).squeeze(0).squeeze(0).numpy()\n",
    "#Instead of call method use explicit sample method\n",
    "warped_vol_F_noPreFilter = batched_dvf1.sample(vol_tensor, mode=\"bilinear\", padding_mode=\"zeros\", warpingModeString=\"pull\",prefilter=False).squeeze(0).squeeze(0).numpy()\n",
    "print(f'warped_vol_F_noPreFilter  object   dtype {warped_vol_F_noPreFilter.dtype},  shape ZYX3 {warped_vol_F_noPreFilter.shape}')\n",
    "\n",
    "# #Display\n",
    "# v1_volumeComparisonViewer3D(\n",
    "#     listVolumes=[src_vol, dst_vol, warped_vol_F_noPreFilter],listLabels=['src', 'dst', 'warped_vol_F_noPreFilter'],\n",
    "#     maxZ0=src_vol.shape[0], maxZ1=src_vol.shape[1], maxZ2=src_vol.shape[2],\n",
    "#     figsize=(12,8), cmap='gray',\n",
    "#     displayColorbar=False, useExternalWindowCenter=True, wMin=-500, wMax=500)\n",
    "\n",
    "v1_volumeComparisonViewer3D(\n",
    "    listVolumes=[src_vol-dst_vol, warped_vol_F_noPreFilter-dst_vol],listLabels=['F-M', 'M*_NoPreFilter-M'],\n",
    "    maxZ0=src_vol.shape[0], maxZ1=src_vol.shape[1], maxZ2=src_vol.shape[2],\n",
    "    figsize=(12,8), cmap='coolwarm',\n",
    "    displayColorbar=False, useExternalWindowCenter=True, wMin=-100, wMax=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warped_vol_interpol_preFilter  object   dtype float32,  shape ZYX3 (590, 512, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfe5b947f89447e9dfd6eea9ac23eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Output(),), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<exampleUtils.v1_volumeComparisonViewer3D at 0x7f27a4fbd8e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#_call_ method => pull warping, no prefilter\n",
    "# warped_vol_interpol_preFilter = batched_dvf2(vol_tensor).squeeze(0).squeeze(0).numpy()\n",
    "# Instead of call method use explicit sample method\n",
    "# warped_vol_interpol_preFilter = batched_dvf2.sample(vol_tensor, mode=\"cubic\", padding_mode=\"zeros\", warpingModeString=\"pull\",prefilter=True).squeeze(0).squeeze(0).numpy()\n",
    "warped_vol_interpol_preFilter = batched_dvf2.sample(vol_tensor, mode=\"bilinear\", padding_mode=\"zeros\", warpingModeString=\"pull\",prefilter=False).squeeze(0).squeeze(0).cpu().numpy()\n",
    "print(f'warped_vol_interpol_preFilter  object   dtype {warped_vol_interpol_preFilter.dtype},  shape ZYX3 {warped_vol_interpol_preFilter.shape}')\n",
    "\n",
    "# #Display\n",
    "# v1_volumeComparisonViewer3D(\n",
    "#     listVolumes=[src_vol, dst_vol, warped_vol_interpol_preFilter],listLabels=['src', 'dst', 'warped_vol_interpol_preFilter'],\n",
    "#     maxZ0=src_vol.shape[0], maxZ1=src_vol.shape[1], maxZ2=src_vol.shape[2],\n",
    "#     figsize=(12,8), cmap='gray',\n",
    "#     displayColorbar=False, useExternalWindowCenter=True, wMin=-500, wMax=500)\n",
    "\n",
    "v1_volumeComparisonViewer3D(\n",
    "    listVolumes=[src_vol-dst_vol, warped_vol_interpol_preFilter-dst_vol],listLabels=['F-M', 'M*_PreFilter-M'],\n",
    "    maxZ0=src_vol.shape[0], maxZ1=src_vol.shape[1], maxZ2=src_vol.shape[2],\n",
    "    figsize=(12,8), cmap='coolwarm',\n",
    "    displayColorbar=False, useExternalWindowCenter=True, wMin=-100, wMax=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/testVIU/lib/python3.9/site-packages/interpol/autograd.py:287: UserWarning: operator() profile_node %176 : int[] = prim::profile_ivalue(%permutation.15)\n",
      " does not have profile information (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/third_party/nvfuser/csrc/graph_fuser.cpp:104.)\n",
      "  output = spline_coeff_nd(input, *opt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warped_vol_interpol  object   dtype float32,  shape ZYX3 (590, 512, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6662c06b62864858b7f2903d8a2fbc9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Output(),), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<exampleUtils.v1_volumeComparisonViewer3D at 0x7f27a32a9760>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dvf1Grid_to_interpol = convertGrid_functional2interpol(batched_dvf1.mapping(), src_vol.shape[0], src_vol.shape[1], src_vol.shape[2])\n",
    "warped_vol_interpol = interpol.grid_pull(vol_tensor, batched_dvf1Grid_to_interpol,interpolation='cubic',bound='zero',prefilter=True).squeeze(0).squeeze(0).cpu().numpy()\n",
    "print(f'warped_vol_interpol  object   dtype {warped_vol_interpol.dtype},  shape ZYX3 {warped_vol_interpol.shape}')\n",
    "\n",
    "#Display\n",
    "v1_volumeComparisonViewer3D(\n",
    "    listVolumes=[src_vol, dst_vol, warped_vol_interpol],listLabels=['src', 'dst', 'warped_vol_interpol'],\n",
    "    maxZ0=src_vol.shape[0], maxZ1=src_vol.shape[1], maxZ2=src_vol.shape[2],\n",
    "    figsize=(12,8), cmap='gray',\n",
    "    displayColorbar=False, useExternalWindowCenter=True, wMin=-500, wMax=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warped_vol_resample_F_warp_interpol  object   dtype float32,  shape ZYX3 (590, 512, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501f2942bc5543588bc6303416f72da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Output(),), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<exampleUtils.v1_volumeComparisonViewer3D at 0x7f27a33a8e20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warped_vol_resample_F_warp_interpol = batched_dvf1.sample(vol_tensor, mode=\"cubic\", padding_mode=\"zeros\", warpingModeString=\"pull\",prefilter=True).squeeze(0).squeeze(0).numpy()\n",
    "print(f'warped_vol_resample_F_warp_interpol  object   dtype {warped_vol_resample_F_warp_interpol.dtype},  shape ZYX3 {warped_vol_resample_F_warp_interpol.shape}')\n",
    "\n",
    "#Display\n",
    "v1_volumeComparisonViewer3D(\n",
    "    listVolumes=[src_vol, dst_vol, warped_vol_F_noPreFilter],listLabels=['src', 'dst', 'warped_vol_resample_F_warp_interpol'],\n",
    "    maxZ0=src_vol.shape[0], maxZ1=src_vol.shape[1], maxZ2=src_vol.shape[2],\n",
    "    figsize=(12,8), cmap='gray',\n",
    "    displayColorbar=False, useExternalWindowCenter=True, wMin=-500, wMax=500)\n",
    "\n",
    "# v1_volumeComparisonViewer3D(\n",
    "#     listVolumes=[src_vol-dst_vol, warped_vol_resample_F_warp_interpol-dst_vol],listLabels=['F-M', 'M*_resamp_F_warp_interpol-M'],\n",
    "#     maxZ0=src_vol.shape[0], maxZ1=src_vol.shape[1], maxZ2=src_vol.shape[2],\n",
    "#     figsize=(12,8), cmap='coolwarm',\n",
    "#     displayColorbar=False, useExternalWindowCenter=True, wMin=-100, wMax=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testVIU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
