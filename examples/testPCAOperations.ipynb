{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted from   /mnt/data/supratik/demonstrateDIR/v2_evalDIRParamDataGeneration.py\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "import os\n",
    "import re\n",
    "from functools import reduce\n",
    "from glob import glob\n",
    "from time import sleep\n",
    "import json\n",
    "import csv\n",
    "import nibabel as nib\n",
    "\n",
    "import imageio #Bose: Imageio is a Python library that provides an easy interface to read and write a wide range of image data, including animated images, volumetric data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm #Bose: matplotlib colormaps and functions\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import Normalize #Bose: The matplotlib.colors module is used for converting color or numbers arguments to RGBA or RGB.This module is used for mapping numbers to colors or color specification conversion in a 1-D array of colors also known as colormap.And Normalize class is used to normalize data into the interval of [0.0, 1.0].\n",
    "from skimage.segmentation import mark_boundaries #Bose: Return image with boundaries between labeled regions highlighted\n",
    "from skimage.transform import rescale #Bose: Rescale operation resizes an image by a given scaling factor. The scaling factor can either be a single floating point value, or multiple values - one along each axis.\n",
    "colormap = cm.hsv\n",
    "norm = Normalize()\n",
    "\n",
    "import pydicom\n",
    "from scipy.ndimage import morphology\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "from viu.io import volume\n",
    "from viu.io.volume import read_volume\n",
    "from viu.torch.deformation.fields import DVF, set_identity_mapping_cache\n",
    "from viu.torch.io.deformation import *\n",
    "from viu.util.body_mask import seg_body\n",
    "from viu.util.memory import fmt_mem_size\n",
    "from viu.util.config import json_config\n",
    "from viu.torch.visualization.ortho_utils import save_ortho_views #from pamomo.visualization.ortho_utils import save_ortho_views\n",
    "from viu.torch.measure.voi import measure_voi_list\n",
    "\n",
    "from pamomo.pca.cmo_pca import CMoPCA\n",
    "from pamomo.registration.deformable import reg, force_unload\n",
    "from pamomo.visualization.cmo_pca_plots import *\n",
    "from pamomo.metrices.residual_deformation import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exampleUtils import *\n",
    "mse = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patientMRN Patient02PB\n",
      "Namespace(vol='/home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin*', pca_fn='/home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/Patient02PB_test_pca.hdf', dvfs=None, cache_dvf_npz_folder='/home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/DVFStore/', vols_fn='Patient02PB_test_vols.hdf', cache='/home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/Cache/', body_seg=True, body_seg_union=True, nifti_body_seg='seg/body.nii.gz', air_threshold=-300, skip=1, skip_idx=None, deferred_resampling=True, force_pca=True, plot=True, reconstructedVol_fn='/home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/Patient02PB_reconstructed_vols.hdf', mean2dcm=True, dirOptionsDict_fn='/home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/dirOptionsDict.json', fps=4, prefilter=True, truncateDepth_initial=50, truncateDepth_final=50)\n"
     ]
    }
   ],
   "source": [
    "workingFolderParent = '/home/wd974888/Downloads'\n",
    "logFilepath = f'{workingFolderParent}/workingFolder/DeformationExperiment/PCA/log.txt'\n",
    "patiendId = 2 #in range(8,9): #range(1,12) #range(1,12) #Use <truncateDepth_initial, final> : Pat01:<50, 50>; Pat02:<50, 50>; Pat04:<0, 0>; Pat07:<95, 95>; Pat09:<200, 100>;\n",
    "binningType = 'PB' # in ['AB']: #['AB', 'PB']\n",
    "patientMRN = f'Patient{patiendId:02d}{binningType}'\n",
    "print(f'patientMRN {patientMRN}')\n",
    "args =  Namespace(\\\n",
    "    vol=f'{workingFolderParent}/workingFolder/DeformationExperiment/PCA/{patientMRN}/StudyAnonymized/bin*',\\\n",
    "    pca_fn=f'{workingFolderParent}/workingFolder/DeformationExperiment/PCA/{patientMRN}/{patientMRN}_test_pca.hdf',\\\n",
    "    dvfs=None,\\\n",
    "    cache_dvf_npz_folder=f'{workingFolderParent}/workingFolder/DeformationExperiment/PCA/{patientMRN}/DVFStore/',\\\n",
    "    vols_fn=f'{patientMRN}_test_vols.hdf',\\\n",
    "    cache=f'{workingFolderParent}/workingFolder/DeformationExperiment/PCA/{patientMRN}/Cache/',\\\n",
    "    body_seg=True,\\\n",
    "    body_seg_union=True,\\\n",
    "    nifti_body_seg='seg/body.nii.gz',\\\n",
    "    air_threshold=-300,\\\n",
    "    skip=1,\\\n",
    "    skip_idx=None,\\\n",
    "    deferred_resampling=True,\\\n",
    "    force_pca=True,\\\n",
    "    plot=True,\\\n",
    "    reconstructedVol_fn=f'{workingFolderParent}/workingFolder/DeformationExperiment/PCA/{patientMRN}/{patientMRN}_reconstructed_vols.hdf',\\\n",
    "    mean2dcm=True,\\\n",
    "    dirOptionsDict_fn=f'{workingFolderParent}/workingFolder/DeformationExperiment/PCA/dirOptionsDict.json',\\\n",
    "    fps=4,\\\n",
    "    prefilter=True,\\\n",
    "    truncateDepth_initial=50,\\\n",
    "    truncateDepth_final=50\\\n",
    "    )\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dvfs is  None: #No Dicom DVF folder  specified\n",
    "    if args.cache_dvf_npz_folder is not None: # cache dvf_npz_folder is specified\n",
    "        #Create folder if not already present\n",
    "        os.makedirs(args.cache_dvf_npz_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(str(args.dirOptionsDict_fn),\"r\") as json_file:\n",
    "    dirOptionsDict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "usingLoopNoForceUnload=True\n",
    "#Before loop over configuration:\n",
    "args.org_pca_fn = args.pca_fn\n",
    "args.org_reconstructedVol_fn = args.reconstructedVol_fn\n",
    "prefilterPrefix = \"Interpol\" if True==args.prefilter else \"Functional\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOES NOT EXISTS /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/gifFolder/Patient02PB_fps_04_Interpol_config01.gif. Will generate gif\n"
     ]
    }
   ],
   "source": [
    "currentDirOptionsKey = f\"config01\" #in [f\"config{i:02d}\" for i in range(10,11)]: #[f\"config{i:02d}\" for i in range(1,11)]\n",
    "behaviourPrefixedConfigKey = f'{prefilterPrefix}_{currentDirOptionsKey}'\n",
    "#Check if the resultGifFilePath already exists. If exists, continue\n",
    "gifFilePath = os.path.join(f'{workingFolderParent}/workingFolder/DeformationExperiment/PCA/gifFolder/',f'{patientMRN}_fps_{args.fps:02d}_{behaviourPrefixedConfigKey}.gif') #{currentDirOptionsKey}.gif\n",
    "gifFilePathOrgVol = os.path.join(f'{workingFolderParent}/workingFolder/DeformationExperiment/PCA/gifFolder/',f'{patientMRN}_fps_{args.fps:02d}_org.gif')\n",
    "if (\"config01\"==currentDirOptionsKey and os.path.exists(gifFilePathOrgVol) and  os.path.exists(gifFilePath))\\\n",
    "    or (\"config01\"!=currentDirOptionsKey and  os.path.exists(gifFilePath)):\n",
    "    resultForThisConfigExists=True\n",
    "    print(f'Exists {gifFilePath}. Moving to next item')\n",
    "else:\n",
    "    resultForThisConfigExists=False\n",
    "    print(f'DOES NOT EXISTS {gifFilePath}. Will generate gif')\n",
    "\n",
    "#Overwrite previous decision\n",
    "runGifCreationFlag=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started working on Interpol_config01_Patient02PB\n"
     ]
    }
   ],
   "source": [
    "# if False==resultForThisConfigExists:\n",
    "######## LOG ######\n",
    "logString = f'Started working on {behaviourPrefixedConfigKey}_{patientMRN}'\n",
    "print(logString)\n",
    "with open(logFilepath, 'r+') as f:\n",
    "    f.seek(0)\n",
    "    f.writelines([logString])\n",
    "    f.truncate()\n",
    "    f.close()\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache file does NOT exist: /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/Cache/Interpol_config01_Patient02PB_test_pca.pt\n"
     ]
    }
   ],
   "source": [
    "# if False==resultForThisConfigExists:\n",
    "currentDirOptions = dirOptionsDict[currentDirOptionsKey]\n",
    "#Update args to include configuration\n",
    "dirName = os.path.dirname(args.org_pca_fn)\n",
    "f_name = os.path.basename(args.org_pca_fn).split('.')[0]\n",
    "f_extension = os.path.basename(args.org_pca_fn).split('.')[1]\n",
    "configurized_pca_fn = os.path.join(dirName, f'{behaviourPrefixedConfigKey}_{f_name}.{f_extension}')\n",
    "args.pca_fn = configurized_pca_fn\n",
    "####\n",
    "args.reconstructedVol_fn = os.path.join(os.path.dirname(args.org_reconstructedVol_fn), f'{behaviourPrefixedConfigKey}_{os.path.basename(args.org_reconstructedVol_fn)}')\n",
    "###\n",
    "############\n",
    "# #Inconsistency check #1. Move here after pca_fn is prepended with configName\n",
    "# if not args.force_pca and os.path.exists(args.pca_fn):\n",
    "#     exit()\n",
    "# ############\n",
    "dst_path = os.path.realpath(dirName)\n",
    "os.makedirs(dst_path, exist_ok=True)\n",
    "name=f'{behaviourPrefixedConfigKey}_{f_name}'\n",
    "vols = None\n",
    "dvfs = None\n",
    "msks = None\n",
    "if args.cache is not None:\n",
    "    cache_fn = os.path.join(args.cache, os.path.splitext(os.path.basename(args.pca_fn))[0] + '.pt')\n",
    "    #If cached filename is present, read vols, dvfs, masks from cached file\n",
    "    if os.path.exists(cache_fn):\n",
    "        print(f'Cache file exists: {cache_fn}')\n",
    "        vols, dvfs, res, pos, dvf_res, dvf_pos, msks, vol_idx_msk = torch.load(cache_fn)\n",
    "        #vols = (10, 590, 512, 512), dvfs = (10, 590, 512, 512, 3) msks(body union) = (1, 590, 512, 512)\n",
    "    else:\n",
    "        print(f'Cache file does NOT exist: {cache_fn}')\n",
    "dst_path_org=dst_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = os.path.join(dst_path, args.vols_fn)\n",
    "# print(f'Writing {fn}...')\n",
    "# with h5py.File(fn, 'w') as hdf:\n",
    "#     volume.add_hdf_volume(hdf, vols.cpu().numpy(), res, pos, hdf_ds_name='volumes')\n",
    "#     volume.add_hdf_volume(hdf, msks.cpu().numpy(), res, pos, hdf_ds_name='masks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org_depth 383 startSlice 50 endSlice 333 new_depth 283\n",
      "Loading /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_01...\n",
      "Loading /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_03...\n",
      "Loading /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_05...\n",
      "Loading /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_07...\n",
      "Loading /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_09...\n",
      "Loading /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_11...\n",
      "Loading /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_13...\n",
      "Loading /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_15...\n",
      "Loading /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_17...\n",
      "Loading /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_19...\n"
     ]
    }
   ],
   "source": [
    "# if False==resultForThisConfigExists:\n",
    "#We are here if  cached filename is NOT present\n",
    "#First read the volumes\n",
    "if vols is None:\n",
    "    vol_fnl = glob(args.vol)\n",
    "    vol_fnl = sort_by_series_number(vol_fnl)\n",
    "\n",
    "    vol_idx_msk = torch.ones(len(vol_fnl), dtype=bool)\n",
    "    if args.skip > 0:\n",
    "        vol_idx_msk[torch.arange(len(vol_idx_msk)) % (args.skip + 1) != 0] = False\n",
    "\n",
    "    if args.skip_idx is not None:\n",
    "        for i in args.skip_idx:\n",
    "            vol_idx_msk[i] = False\n",
    "\n",
    "    vol_fnl = [vol_fnl[i] for i, b in enumerate(vol_idx_msk) if b]\n",
    "\n",
    "    #########\n",
    "    tmp_vol, _, _ = read_volume(vol_fnl[0])\n",
    "    org_depth=tmp_vol.shape[0]\n",
    "    startSlice=args.truncateDepth_initial\n",
    "    endSlice=org_depth - args.truncateDepth_final\n",
    "    new_depth = org_depth - args.truncateDepth_initial - args.truncateDepth_final\n",
    "    print(f'org_depth {org_depth} startSlice {startSlice} endSlice {endSlice} new_depth {new_depth}')\n",
    "    #########\n",
    "    vol_lst = []\n",
    "    for vfn in vol_fnl:\n",
    "        print(f'Loading {vfn}...')\n",
    "        vol, res, pos = read_volume(vfn)\n",
    "        ######\n",
    "        vol=vol[startSlice:endSlice, ...]\n",
    "        ######\n",
    "        vol_lst.append(torch.Tensor(vol)[None, ...])\n",
    "    vols = torch.concatenate(vol_lst, dim=0)\n",
    "    del vol_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d45205ad6e41ec8e51395f57790cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Output(),), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<exampleUtils.v1_volumeComparisonViewer3D at 0x7f0175ed8fa0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us display one bin\n",
    "from exampleUtils import *\n",
    "display_vol = vols[0,...].cpu().numpy()\n",
    "v1_volumeComparisonViewer3D(\n",
    "    listVolumes=[display_vol],listLabels=[f'{patientMRN}_bin00'],\n",
    "    maxZ0=display_vol.shape[0], maxZ1=display_vol.shape[1], maxZ2=display_vol.shape[2],\n",
    "    figsize=(12,8), cmap='gray',\n",
    "    displayColorbar=False, useExternalWindowCenter=True, wMin=-500, wMax=500, useAspectCol=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load body segmentation: /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_01/seg/body.nii.gz...\n",
      "msk shape torch.Size([1, 283, 512, 512])\n",
      "Load body segmentation: /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_03/seg/body.nii.gz...\n",
      "msk shape torch.Size([1, 283, 512, 512])\n",
      "Load body segmentation: /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_05/seg/body.nii.gz...\n",
      "msk shape torch.Size([1, 283, 512, 512])\n",
      "Load body segmentation: /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_07/seg/body.nii.gz...\n",
      "msk shape torch.Size([1, 283, 512, 512])\n",
      "Load body segmentation: /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_09/seg/body.nii.gz...\n",
      "msk shape torch.Size([1, 283, 512, 512])\n",
      "Load body segmentation: /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_11/seg/body.nii.gz...\n",
      "msk shape torch.Size([1, 283, 512, 512])\n",
      "Load body segmentation: /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_13/seg/body.nii.gz...\n",
      "msk shape torch.Size([1, 283, 512, 512])\n",
      "Load body segmentation: /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_15/seg/body.nii.gz...\n",
      "msk shape torch.Size([1, 283, 512, 512])\n",
      "Load body segmentation: /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_17/seg/body.nii.gz...\n",
      "msk shape torch.Size([1, 283, 512, 512])\n",
      "Load body segmentation: /home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/StudyAnonymized/bin_19/seg/body.nii.gz...\n",
      "msk shape torch.Size([1, 283, 512, 512])\n",
      "Start registration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the Fraunhofer MEVIS cuda registration library. Version: VarianDeformableRegistrationDLLCUDA -- v1.6.2, built Dec 11 2023, 20:49:53\n",
      "numSourceSegments <= 0. Running without mask alignment. Continuing.\n",
      "Started registration...\n",
      "Optimization on level 1 / 3 needs: 0.595635 s\n",
      "Optimization on level 2 / 3 needs: 5.20313 s\n",
      "Optimization on level 3 / 3 needs: 34.6421 s\n",
      "Finished multilevel registration.\n",
      "Total runtime: 42.1874s.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start registration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the Fraunhofer MEVIS cuda registration library. Version: VarianDeformableRegistrationDLLCUDA -- v1.6.2, built Dec 11 2023, 20:49:53\n",
      "numSourceSegments <= 0. Running without mask alignment. Continuing.\n",
      "Started registration...\n",
      "Optimization on level 1 / 3 needs: 0.648282 s\n",
      "Optimization on level 2 / 3 needs: 5.21768 s\n",
      "Optimization on level 3 / 3 needs: 34.6938 s\n",
      "Finished multilevel registration.\n",
      "Total runtime: 42.0961s.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start registration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the Fraunhofer MEVIS cuda registration library. Version: VarianDeformableRegistrationDLLCUDA -- v1.6.2, built Dec 11 2023, 20:49:53\n",
      "numSourceSegments <= 0. Running without mask alignment. Continuing.\n",
      "Started registration...\n",
      "Optimization on level 1 / 3 needs: 0.648009 s\n",
      "Optimization on level 2 / 3 needs: 6.167 s\n",
      "Optimization on level 3 / 3 needs: 38.006 s\n",
      "Finished multilevel registration.\n",
      "Total runtime: 46.1514s.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start registration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the Fraunhofer MEVIS cuda registration library. Version: VarianDeformableRegistrationDLLCUDA -- v1.6.2, built Dec 11 2023, 20:49:53\n",
      "numSourceSegments <= 0. Running without mask alignment. Continuing.\n",
      "Started registration...\n",
      "Optimization on level 1 / 3 needs: 0.57494 s\n",
      "Optimization on level 2 / 3 needs: 8.17887 s\n",
      "Optimization on level 3 / 3 needs: 55.1103 s\n",
      "Finished multilevel registration.\n",
      "Total runtime: 65.1944s.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start registration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the Fraunhofer MEVIS cuda registration library. Version: VarianDeformableRegistrationDLLCUDA -- v1.6.2, built Dec 11 2023, 20:49:53\n",
      "numSourceSegments <= 0. Running without mask alignment. Continuing.\n",
      "Started registration...\n",
      "Optimization on level 1 / 3 needs: 0.70158 s\n",
      "Optimization on level 2 / 3 needs: 7.4533 s\n",
      "Optimization on level 3 / 3 needs: 51.9312 s\n",
      "Finished multilevel registration.\n",
      "Total runtime: 61.4101s.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start registration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the Fraunhofer MEVIS cuda registration library. Version: VarianDeformableRegistrationDLLCUDA -- v1.6.2, built Dec 11 2023, 20:49:53\n",
      "numSourceSegments <= 0. Running without mask alignment. Continuing.\n",
      "Started registration...\n",
      "Optimization on level 1 / 3 needs: 0.734306 s\n",
      "Optimization on level 2 / 3 needs: 6.70418 s\n",
      "Optimization on level 3 / 3 needs: 54.3675 s\n",
      "Finished multilevel registration.\n",
      "Total runtime: 63.129s.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start registration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the Fraunhofer MEVIS cuda registration library. Version: VarianDeformableRegistrationDLLCUDA -- v1.6.2, built Dec 11 2023, 20:49:53\n",
      "numSourceSegments <= 0. Running without mask alignment. Continuing.\n",
      "Started registration...\n",
      "Optimization on level 1 / 3 needs: 0.702675 s\n",
      "Optimization on level 2 / 3 needs: 6.51639 s\n",
      "Optimization on level 3 / 3 needs: 55.0073 s\n",
      "Finished multilevel registration.\n",
      "Total runtime: 63.5529s.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start registration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the Fraunhofer MEVIS cuda registration library. Version: VarianDeformableRegistrationDLLCUDA -- v1.6.2, built Dec 11 2023, 20:49:53\n",
      "numSourceSegments <= 0. Running without mask alignment. Continuing.\n",
      "Started registration...\n",
      "Optimization on level 1 / 3 needs: 0.885663 s\n",
      "Optimization on level 2 / 3 needs: 5.60512 s\n",
      "Optimization on level 3 / 3 needs: 37.2905 s\n",
      "Finished multilevel registration.\n",
      "Total runtime: 45.1135s.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start registration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the Fraunhofer MEVIS cuda registration library. Version: VarianDeformableRegistrationDLLCUDA -- v1.6.2, built Dec 11 2023, 20:49:53\n",
      "numSourceSegments <= 0. Running without mask alignment. Continuing.\n",
      "Started registration...\n",
      "Optimization on level 1 / 3 needs: 0.697237 s\n",
      "Optimization on level 2 / 3 needs: 5.42843 s\n",
      "Optimization on level 3 / 3 needs: 35.2214 s\n",
      "Finished multilevel registration.\n",
      "Total runtime: 42.6879s.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start registration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the Fraunhofer MEVIS cuda registration library. Version: VarianDeformableRegistrationDLLCUDA -- v1.6.2, built Dec 11 2023, 20:49:53\n",
      "numSourceSegments <= 0. Running without mask alignment. Continuing.\n",
      "Started registration...\n",
      "Optimization on level 1 / 3 needs: 0.774876 s\n",
      "Optimization on level 2 / 3 needs: 5.82816 s\n",
      "Optimization on level 3 / 3 needs: 40.4485 s\n",
      "Finished multilevel registration.\n",
      "Total runtime: 48.3808s.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# if False==resultForThisConfigExists:\n",
    "#We are here if  cached filename is NOT present\n",
    "#Now read / compute DVFs\n",
    "if dvfs is None:\n",
    "    dvf_lst = []\n",
    "    #If DICOM DVF filename list is available, the DVFs are read from there.\n",
    "    if args.dvfs is not None:\n",
    "        dvf_fnl = glob(args.dvfs)\n",
    "        for dfn in dvf_fnl:\n",
    "            print(f'Loading {dfn}...')\n",
    "            dvf, dvf_res, dvf_pos = read_nr_dcm(dfn, vol_dim=vol.shape[::-1], vol_res=res, vol_pos=pos)\n",
    "            dvf_lst.append(DVF(torch.Tensor(dvf)[None, ...]))\n",
    "    #Otherwise  look for DVFs from npz file cache if specified or run DIR\n",
    "    else:\n",
    "        #Fist though get the body mask of each scans and if needed make\n",
    "        vol_min = -1200\n",
    "        cnt = vols.shape[0]\n",
    "        dst_dim = torch.tensor(vols[0].squeeze().shape[::-1])\n",
    "        dst_res = torch.tensor(res, dtype=torch.float64)\n",
    "        msk_lst = []\n",
    "        if args.body_seg:\n",
    "            for i in range(cnt):\n",
    "                #Mask is always obtained on the untruncated volume and then truncated as trying to obtain mask on truncated volume is giving empty mask!!!\n",
    "                if args.nifti_body_seg is not None:\n",
    "                    fn = os.path.join(vol_fnl[i], args.nifti_body_seg)\n",
    "                    print(f'Load body segmentation: {fn}...')\n",
    "                    ####\n",
    "                    # msk = torch.tensor(nib.load(fn).get_fdata()).to(bool).permute(2, 1, 0).flip(1)[None, ...]\n",
    "                    # Truncate as needed\n",
    "                    msk = torch.tensor(nib.load(fn).get_fdata()).to(bool).permute(2, 1, 0).flip(1)[startSlice:endSlice, ...][None, ...]\n",
    "                    ####\n",
    "                else:\n",
    "                    print('Find connected components...')\n",
    "                    msk = torch.tensor(seg_body(vols[(i + 1) % cnt], args.air_threshold, air_dilation=4))\n",
    "                print(f'msk shape {msk.shape}')\n",
    "                msk_lst.append(msk)\n",
    "            msks = torch.concatenate(msk_lst, dim=0)\n",
    "            del msk_lst\n",
    "\n",
    "            if args.body_seg_union:\n",
    "                msks = reduce(lambda a, b: a.bitwise_or(b), msks)[None, ...]\n",
    "                # hack to fill disconnected air components at the volume borders\n",
    "                from skimage import measure\n",
    "                label = measure.label(torch.bitwise_not(msks).numpy())\n",
    "                idx, label_cnt = np.unique(label, return_counts=True)\n",
    "                idx = idx[np.argsort(label_cnt)[:-1]]\n",
    "                for i in idx:\n",
    "                    #Exception in PyTorch 2.2 env: IndexError: The shape of the mask [1, 590, 512, 512] at index 0 does not match the shape of the indexed tensor [590, 512, 512] at index 0\n",
    "                    #Because msks[0].shape = [590, 512, 512], But [label == i].shape = [1, 590, 512, 512]\n",
    "                    msks[0][label == i] = True #Replaced [0] to remove exception in Baden environment #msks[0][label == i] = True\n",
    "                # ---\n",
    "\n",
    "        co_dvf_res = None\n",
    "        co_dvf_pos = None\n",
    "        #Now compute cyclic DVFs.\n",
    "        for i in range(cnt):\n",
    "            #However before running DIR check whether it has been pre-computed and saved as npz file\n",
    "            dvfFileName=''\n",
    "            if (args.cache_dvf_npz_folder is not None):\n",
    "                from_scanName = os.path.basename(vol_fnl[i])\n",
    "                to_scanName = os.path.basename(vol_fnl[(i + 1) % cnt])\n",
    "                #NOTE dvfs themselves are initially generated from MEVIS and do not depend on functiona / interpol and hence \n",
    "                # instead of behaviourPrefixedConfigKey, they are named with just currentDirOptionsKey\n",
    "                dvfFileName = os.path.join(args.cache_dvf_npz_folder, f'{currentDirOptionsKey}_dvf_from_{from_scanName}_to_{to_scanName}.npz')\n",
    "\n",
    "            if(os.path.exists(dvfFileName)):\n",
    "                dvfBatch = np.load(dvfFileName)\n",
    "                dvf = dvfBatch['arr_0']\n",
    "                dvf_res = dvfBatch['arr_1']\n",
    "                dvf_pos =  dvfBatch['arr_2']\n",
    "            else:\n",
    "                src_seg_dict = {}\n",
    "                dst_seg_dict  = {}\n",
    "\n",
    "                src_seg_list = currentDirOptions[\"src_seg\"]\n",
    "                dst_seg_list = currentDirOptions[\"dst_seg\"]\n",
    "                alpha_DIR = currentDirOptions[\"alpha\"]\n",
    "                beta_DIR = currentDirOptions[\"beta\"]\n",
    "                gamma_DIR = currentDirOptions[\"gamma\"]\n",
    "                dvfRes = currentDirOptions[\"dvfRes\"]\n",
    "                prefix = currentDirOptions[\"prefix\"]\n",
    "                if\"default\"==dvfRes:\n",
    "                    numLevels=3 #=default value =3\n",
    "                    finestLevelReference=1 #=default value =1 => DVF computed at half resolution of volume\n",
    "                    finestLevelTemplate=1  # =default value = 1 => DVF computed at half resolution of volume\n",
    "                elif\"low\"==dvfRes:\n",
    "                    numLevels=3\n",
    "                    finestLevelReference=2\n",
    "                    finestLevelTemplate=2\n",
    "                elif\"high\"==dvfRes:\n",
    "                    numLevels=4\n",
    "                    finestLevelReference=0\n",
    "                    finestLevelTemplate=0\n",
    "                else:\n",
    "                    print('Unacceptable dvf resolution.')\n",
    "                    exit()\n",
    "\n",
    "                if \"SG_lungs\" in src_seg_list and \"SG_lungs\" in dst_seg_list:\n",
    "                    src_lungs_fn = os.path.join(vol_fnl[i], 'seg/lung.nii.gz')\n",
    "                    src_lungs_np = torch.tensor(nib.load(src_lungs_fn).get_fdata()).to(bool).permute(2, 1, 0).flip(1).numpy() #np.transpose(nib.load(src_lungs_fn).get_fdata(), (2,1,0)).astype('uint8').astype('bool')\n",
    "                    src_seg_dict[\"SG_lungs\"]=src_lungs_np\n",
    "                    dst_lungs_fn = os.path.join(vol_fnl[(i + 1) % cnt], 'seg/lung.nii.gz')\n",
    "                    dst_lungs_np = torch.tensor(nib.load(dst_lungs_fn).get_fdata()).to(bool).permute(2, 1, 0).flip(1).numpy() #np.transpose(nib.load(dst_lungs_fn).get_fdata(), (2,1,0)).astype('uint8').astype('bool')\n",
    "                    dst_seg_dict[\"SG_lungs\"]=dst_lungs_np\n",
    "\n",
    "                if \"LR_dst_bones\" in dst_seg_list:\n",
    "                    dst_bones_fn = os.path.join(vol_fnl[(i + 1) % cnt], 'seg/bone.nii.gz')\n",
    "                    dst_bones_np = torch.tensor(nib.load(dst_bones_fn).get_fdata()).to(bool).permute(2, 1, 0).flip(1).numpy() #np.transpose(nib.load(dst_bones_fn).get_fdata(), (2,1,0)).astype('uint8').astype('bool')\n",
    "                    dst_seg_dict[\"LR_dst_bones\"]=dst_bones_np\n",
    "\n",
    "                if \"LR_dst_vertebra\" in dst_seg_list:\n",
    "                    dst_vertebra_fn = os.path.join(vol_fnl[(i + 1) % cnt], 'seg/vertebra_combined.nii.gz')\n",
    "                    dst_vertebra_np = torch.tensor(nib.load(dst_vertebra_fn).get_fdata()).to(bool).permute(2, 1, 0).flip(1).numpy() #np.transpose(nib.load(dst_bones_fn).get_fdata(), (2,1,0)).astype('uint8').astype('bool')\n",
    "                    dst_seg_dict[\"LR_dst_vertebra\"]=dst_vertebra_np\n",
    "\n",
    "                if \"CJ_dst_lungs\" in dst_seg_list:\n",
    "                    dst_lungs_fn = os.path.join(vol_fnl[(i + 1) % cnt], 'seg/lung.nii.gz')\n",
    "                    dst_lungs_np = torch.tensor(nib.load(dst_lungs_fn).get_fdata()).to(bool).permute(2, 1, 0).flip(1).numpy() #np.transpose(nib.load(dst_lungs_fn).get_fdata(), (2,1,0)).astype('uint8').astype('bool')\n",
    "                    dst_seg_dict[\"CJ_dst_lungs\"]=dst_lungs_np\n",
    "\n",
    "                if args.body_seg:\n",
    "                    dst_seg_dict[\"SM_bodymask\"]=msks[min(i, msks.shape[0]-1)].numpy()\n",
    "\n",
    "                additional_args = {}\n",
    "                if len(src_seg_dict) > 0:\n",
    "                    additional_args['src_seg'] = src_seg_dict\n",
    "                if len(dst_seg_dict) > 0:\n",
    "                    additional_args['dst_seg'] = dst_seg_dict\n",
    "                if args.body_seg:\n",
    "                    additional_args['similarityMaskMultilevelStrategy'] = 'STRICTINTERIOR'\n",
    "\n",
    "                print('Start registration...')\n",
    "                if\"default\"==dvfRes:\n",
    "                    dvf, dvf_res, dvf_pos = reg(vols[i].clip(min=vol_min).squeeze().numpy(), res,\n",
    "                        vols[(i + 1) % cnt].clip(min=vol_min).squeeze().numpy(), res,\n",
    "                        alpha=alpha_DIR, #20\n",
    "                        maskAlignmentWeight=beta_DIR,\n",
    "                        # numLevels=3, #=default value =3\n",
    "                        # finestLevelReference=1, #=default value =1 => DVF computed at half resolution of volume\n",
    "                        # finestLevelTemplate=1,  # =default value = 1 => DVF computed at half resolution of volume\n",
    "                        constantJacobianWeight=gamma_DIR,\n",
    "                        # verboseMode='false',\n",
    "                        **additional_args)\n",
    "                else:\n",
    "                    dvf, dvf_res, dvf_pos = reg(vols[i].clip(min=vol_min).squeeze().numpy(), res,\n",
    "                        vols[(i + 1) % cnt].clip(min=vol_min).squeeze().numpy(), res,\n",
    "                        alpha=alpha_DIR, #20\n",
    "                        maskAlignmentWeight=beta_DIR,\n",
    "                        numLevels=numLevels,\n",
    "                        finestLevelReference=finestLevelReference,\n",
    "                        finestLevelTemplate=finestLevelTemplate,\n",
    "                        constantJacobianWeight=gamma_DIR,\n",
    "                        # verboseMode='false',\n",
    "                        **additional_args)\n",
    "\n",
    "                #Save dvf if we have run DIR and dvfFileName is not ''\n",
    "                if (dvfFileName !='' and False==os.path.exists(dvfFileName)):\n",
    "                    np.savez_compressed(dvfFileName, dvf, dvf_res, dvf_pos)\n",
    "\n",
    "            dvf_res = torch.tensor(dvf_res, dtype=torch.float64)\n",
    "            dvf_pos = torch.tensor(dvf_pos, dtype=torch.float64)\n",
    "            #dvf.shape before resampling (295, 256, 256, 3)\n",
    "            dvf = DVF(dvf[None,...]).from_millimeter(dvf_res).to(torch.float32) #Adding batch before constructing DVF object\n",
    "            if not args.deferred_resampling:\n",
    "                dvf = dvf.resample(dst_dim, dst_res, dvf_res=dvf_res, dvf_pos=dvf_pos, prefilter=args.prefilter, mode='cubic' if True==args.prefilter else 'bilinear') #TODO\n",
    "            else:\n",
    "                if co_dvf_res is None:\n",
    "                    co_dvf_res, co_dvf_pos = dvf_res, dvf_pos\n",
    "                else:\n",
    "                    assert torch.equal(dvf_res, co_dvf_res)\n",
    "                    assert torch.equal(dvf_pos, co_dvf_pos)\n",
    "\n",
    "            dvf_lst.append(dvf[None, ...])# In new build_cyclic_pca.py, with bi_cycle=False, this line is equivalent to dvf_lst.append(cc_dvf[None, None, ...])\n",
    "\n",
    "    dvfs = torch.concatenate(dvf_lst, dim=1) ## In new build_cyclic_pca.py, with bi_cycle=False,  #With deferred resampling, dvfs.shape= torch.Size([1, 10, 105, 256, 256, 3])\n",
    "    del dvf_lst\n",
    "\n",
    "    # Moved before memory clean-up\n",
    "    if args.cache is not None:\n",
    "        os.makedirs(os.path.realpath(os.path.dirname(cache_fn)), exist_ok=True)\n",
    "        torch.save((vols, dvfs, res, pos, dvf_res, dvf_pos, msks, vol_idx_msk), cache_fn)# torch.save((vols, dvfs, res, pos, dvf_res, dvf_pos, msks), cache_fn)\n",
    "\n",
    "    if False==usingLoopNoForceUnload:\n",
    "        ##########################\n",
    "        force_unload() #<-------- This is destroying the global variable _dir_lab so in the next loop of the for blocck registration is caching,  \n",
    "        #                # Will see if invoking _dir_lib  from pamomo.registration.deformable fixes that.\n",
    "        #                # Or may be move it out of the loop? or not call?\n",
    "        free_mem, total_mem = 0, 1\n",
    "        while free_mem / total_mem < 0.98:\n",
    "            free_mem, total_mem = torch.cuda.mem_get_info()\n",
    "            print(f'Memory free: {fmt_mem_size(free_mem)}, total: {fmt_mem_size(total_mem)} {free_mem / total_mem:.2%}')\n",
    "            sleep(1)\n",
    "        ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /mnt/DVFStore/PCA/Patient02PB/Patient02PB_test_vols.hdf...\n"
     ]
    }
   ],
   "source": [
    "# if False==resultForThisConfigExists:\n",
    "if args.vols_fn is not None:\n",
    "    fn = os.path.join(dst_path, args.vols_fn)\n",
    "    if False==os.path.exists(fn):\n",
    "        print(f'Writing {fn}...')\n",
    "        with h5py.File(fn, 'w') as hdf:\n",
    "            volume.add_hdf_volume(hdf, vols.cpu().numpy(), res, pos, hdf_ds_name='volumes')\n",
    "            volume.add_hdf_volume(hdf, msks.cpu().numpy(), res, pos, hdf_ds_name='masks')\n",
    "    else:\n",
    "        print(f'Already exists {fn}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wd974888/Downloads/workingFolder/DeformationExperiment/PCA/Patient02PB/Cache/Interpol_config01_Patient02PB_test_pca.pt'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createOrOverwritePCAFlag=False\n",
    "if False==os.path.exists(args.pca_fn):\n",
    "    createOrOverwritePCAFlag=True\n",
    "print(f'createOrOverwritePCAFlag {createOrOverwritePCAFlag}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True==createOrOverwritePCAFlag:\n",
    "    print(f'Running PCA  operation')\n",
    "    set_identity_mapping_cache(True)\n",
    "    pca_msk = None\n",
    "    if msks is not None:\n",
    "        pca_msk = reduce(lambda a, b: a.bitwise_or(b), msks) #shape: D,H,W\n",
    "\n",
    "\n",
    "    cnt = dvfs.shape[0] #dvfs.shape: (NBins, D, H, W, 3)\n",
    "\n",
    "    pca = CMoPCA(example_msk=vol_idx_msk,prefilter=args.prefilter) #vol_idx_msk : [ True, False, Tue, false,... totalBins]\n",
    "    assert dvfs.shape[0] == 1, f'With bi-cycle=False, dvfs.shape=[1, NBins, D*, H*, W*, 3]'\n",
    "    star_dvfs = pca.cycle_to_star_dvfs(dvfs[0].cuda())\n",
    "    # else:\n",
    "    #     res_vols = pca.resample_vols(vols.cuda(), res, pos, dvfs.shape[-4:-1], dvf_res, dvf_pos) #vols.shape [NBin, D, H, W] dvfs.shape = [NBin, D', H', W', 3]\n",
    "\n",
    "    #     star_dvfs, mse_lst = pca.bicycle_to_star_dvfs(dvfs.cuda(), res_vols)\n",
    "    #     if args.plot:\n",
    "    #         vmax = mse_lst.max()\n",
    "    #         fig, ax = plt.subplots(2)\n",
    "    #         ax[0].imshow(mse_lst[0], vmax=vmax)\n",
    "    #         ax[1].imshow(mse_lst[1], vmax=vmax)\n",
    "    #         fig.savefig(os.path.join(dst_path, f'{name}_bicycle_mse.png'))\n",
    "    #         plt.close(fig)\n",
    "\n",
    "\n",
    "    pca.from_star(vols, res, pos, star_dvfs, dvf_res, dvf_pos, body_msk=pca_msk)\n",
    "    log, residuals = pca.reconstruct_mean(vols, iterations=1000)\n",
    "\n",
    "    pca.write(args.pca_fn)\n",
    "\n",
    "    if args.plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title(f'{name} Convergence')\n",
    "        ax.plot(log, color='blue')\n",
    "        ax.tick_params(axis='y', labelcolor='blue')\n",
    "        ax.set_ylabel('HU$^2$')\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(np.diff(log), color='lightblue')\n",
    "        ax2.tick_params(axis='y', labelcolor='lightblue')\n",
    "        ax2.set_ylabel('$\\Delta$ HU$^2$')\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(dst_path, f'{name}_conv.png'))\n",
    "        # plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title(f'{name} Residual MSE')\n",
    "        ax.bar(range(len(residuals)), residuals)\n",
    "        ax.set_xlabel('Bin')\n",
    "        ax.set_ylabel('HU$^2$')\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(dst_path, f'{name}_residuals.png'))\n",
    "        # plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "else:\n",
    "    #Read PCA file\n",
    "    print(f'Reading pre-created PCA  operation')\n",
    "    pca = CMoPCA(example_msk=vol_idx_msk,prefilter=args.prefilter)\n",
    "    mean, res, pos = pca.read(args.pca_fn, device='cuda') #mean.shape torch.Size([590, 512, 512]) #NOTE read mean volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True==runGifCreationFlag:\n",
    "    #Code added to build_cyclic_pca.py\n",
    "    ######## LOG ######\n",
    "    logString = f'Writing mean volume for  {behaviourPrefixedConfigKey}_{patientMRN}'\n",
    "    print(logString)\n",
    "    with open(logFilepath, 'r+') as f:\n",
    "        f.seek(0)\n",
    "        f.writelines([logString])\n",
    "        f.truncate()\n",
    "        f.close()\n",
    "    ###################\n",
    "    args.amplitude_gated = (\"AB_\" in f_name)\n",
    "    dst_path_subdir = os.path.join(dst_path, f'{behaviourPrefixedConfigKey}_amp' if args.amplitude_gated else f'{behaviourPrefixedConfigKey}_phase')\n",
    "    os.makedirs(dst_path_subdir, exist_ok=True)\n",
    "    # mean, res, pos = pca.read(args.pca_fn, device='cuda') #mean.shape torch.Size([590, 512, 512]) #NOTE read mean volume\n",
    "    mean, res, pos =  pca.mean_vol, pca.res, pca.pos\n",
    "    print(f'mean vol shape and device {mean.shape} {mean.device} res {res} pos {pos}')\n",
    "    #Write mean volume\n",
    "    if args.mean2dcm:\n",
    "        # volume.write_dcm(dst_path, 'mean_dcm', mean, res, pos)\n",
    "        volume.write_dcm(dst_path_subdir, 'mean_dcm', mean.detach().cpu().numpy(), res, pos)\n",
    "\n",
    "    #Compute reconstructed volumes\n",
    "    ######## LOG ######\n",
    "    logString = f'Creating and writing reconstructed phase volumes for  {behaviourPrefixedConfigKey}_{patientMRN}'\n",
    "    print(logString)\n",
    "    with open(logFilepath, 'r+') as f:\n",
    "        f.seek(0)\n",
    "        f.writelines([logString])\n",
    "        f.truncate()\n",
    "        f.close()\n",
    "    ###################    vols = torch.tensor(vols, device=mean.device)\n",
    "    reconstructed_vol_lst = []\n",
    "    for i in range(vols.shape[0]):\n",
    "        ref_vol = vols[i].to(mean.device)\n",
    "        print(f'Index: {i} ref_vol shape and device {ref_vol.shape} {ref_vol.device}')\n",
    "        ref_dvf = pca.dvf(pca.vt[i, :]).to(mean.device)\n",
    "        print(f'Index: {i} ref_dvf shape and device {ref_dvf.shape} {ref_dvf.device}')\n",
    "        reconstructedPhaseVol = DVF(ref_dvf[None,...]).sample(mean[None, None,...],prefilter=args.prefilter, mode='cubic' if True==args.prefilter else 'bilinear' ).squeeze().squeeze() #reconstructedPhaseVol = DVF(ref_dvf)(mean)\n",
    "        print(f'Index: {i} reconstructedPhaseVol shape and device {reconstructedPhaseVol.shape}  {reconstructedPhaseVol.device} ')\n",
    "        reconstructed_vol_lst.append(reconstructedPhaseVol[None, ...].cpu().numpy())\n",
    "    reconstructed_vols = np.concatenate(reconstructed_vol_lst, axis=0)\n",
    "    with h5py.File(args.reconstructedVol_fn, 'w') as hdf:\n",
    "        volume.add_hdf_volume(hdf, reconstructed_vols, res, pos, hdf_ds_name='volumes')\n",
    "        print(f'Finished writing {args.reconstructedVol_fn}')\n",
    "    ####### Tensorify and transfer to GPU before gif generation\n",
    "    vols=vols.to(mean.device)\n",
    "    reconstructed_vols=torch.tensor(reconstructed_vols, device=mean.device)\n",
    "    del reconstructed_vol_lst\n",
    "    del mean\n",
    "    ###### Generate gif file for this config\n",
    "    generateGifFile(patientParentFolder=f'{workingFolderParent}/workingFolder/DeformationExperiment/PCA/',\n",
    "        patientMRN=patientMRN, behaviourPrefixedConfigKey=behaviourPrefixedConfigKey, vols=reconstructed_vols, diff_vols= reconstructed_vols-vols, res=res, pos=pos, fps=args.fps, logFilepath=logFilepath)\n",
    "    if \"config01\"==currentDirOptionsKey:\n",
    "        #For the first configuration also generate gif file with original phase volumes\n",
    "        generateGifFile(patientParentFolder=f'{workingFolderParent}/workingFolder/DeformationExperiment/PCA/',\n",
    "            patientMRN=patientMRN, behaviourPrefixedConfigKey='org', vols=vols, diff_vols= vols-vols, res=res, pos=pos, fps=args.fps, logFilepath=logFilepath)\n",
    "\n",
    "    #Memory clean up\n",
    "    del reconstructed_vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalPCAFlag=False\n",
    "if True==evalPCAFlag:\n",
    "    args.dir=True\n",
    "    args.dvf=True\n",
    "    args.maximum_mag=None\n",
    "    dst_path=dst_path_org\n",
    "    print(f'original dst_path {dst_path}')\n",
    "    args.amplitude_gated = (\"AB_\" in f_name)\n",
    "    dst_path = os.path.join(dst_path, f'{behaviourPrefixedConfigKey}_amp' if args.amplitude_gated else f'{behaviourPrefixedConfigKey}_phase')\n",
    "    print(f'new dst_path {dst_path}')\n",
    "    os.makedirs(dst_path, exist_ok=True)\n",
    "    stats_path = 'dvf_stats'\n",
    "    os.makedirs(os.path.join(dst_path, stats_path), exist_ok=True)\n",
    "    comp_dir = args.dir\n",
    "    air_threshold = args.air_threshold #-300\n",
    "\n",
    "    cfg = json_config(os.path.splitext(args.pca_fn)[0] + '.json')  #NOTE create json file for edge measurement\n",
    "    if 'views' not in cfg.keys:\n",
    "        cfg.add_config_item('views', [{'ctr': pos.tolist(), 'voi': None, 'wl': [500, 0]}])\n",
    "        cfg.write()\n",
    "\n",
    "    if 'edge_measurements' not in cfg.keys:\n",
    "        cfg.add_config_item('edge_measurements', [])\n",
    "        cfg.write()\n",
    "\n",
    "    if 'maximum_mag' not in cfg.keys or args.maximum_mag is not None:\n",
    "        cfg.add_config_item('maximum_mag', args.maximum_mag)\n",
    "        cfg.write()\n",
    "\n",
    "    dims = 3\n",
    "    steps = [-3, -2, -1, 0, 1, 2, 3]\n",
    "    for i in range(dims):\n",
    "        a = torch.zeros(dims, device=pca.mean_vol.device)  #Should this be outside for i in range(dims) loop?\n",
    "        for idx, wgt in enumerate(steps):\n",
    "            a[i] = wgt / np.sqrt(pca.example_count) #a: vector of size dim, all values 0 except a[i]=steps[j]/sqrt(exampleCount)\n",
    "            pca_vol = pca.vol(a) #pca.vol(a) = self.dvf(a)(self.mean_vol) \n",
    "            save_ortho_views(f'pc {i} sigma {wgt}', pca_vol, res, pos,\n",
    "                            dst_path=os.path.join(dst_path, 'principal_components'),\n",
    "                            fn=f'pc_{i:03}_{idx:03}_vol.png', views=cfg.views)\n",
    "\n",
    "    A, p = pca.cyclic_parametrization(phase_gated=not args.amplitude_gated) #A.shape: [9,2] p.shape [2,10] \n",
    "    fig, ax = plot_params(p,pca.example_indices)\n",
    "    fig.savefig(os.path.join(dst_path, 'parametrization.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "    vt_hat = (A @ p).transpose(1, 0) #[9,2]*[2,10]transpose(1, 0) =>  [10,9] : vt_hat.shape  : 10 volumes, 9 PC co-efficients /volume\n",
    "    min_pc = 0.5\n",
    "    pcc, relevant = pca.relevant_parameters(vt_hat, min_pc)\n",
    "    pcc, relevant = pcc.cpu(), relevant.cpu() #pcc.shape [9] relevant.shape [9]\n",
    "    relevant_cnt = int(relevant.sum()) #2\n",
    "\n",
    "    fig, ax = plot_parameter_fit(pca.vt, vt_hat, pca.example_indices, pcc, relevant, min_pc)\n",
    "    ax.set_xlabel(f'4D {\"Amplitude Bin\" if args.amplitude_gated else \"Phase\"}')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(dst_path, 'param_fitting.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Component')\n",
    "    ax1.set_ylabel('Standard Deviation (PCA)', color=color)\n",
    "    ax1.plot(pca.std.cpu(), color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:green'\n",
    "    ax2.set_ylabel('Correlation Coefficient (Parametrization)', color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(pcc.cpu(), 'o', color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    fig.savefig(os.path.join(dst_path, 'pca_std_pcc.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "    # vols_path = os.path.join(os.path.realpath(dirName), args.vols_fn)\n",
    "    # args.vols_fn = vols_path\n",
    "    # print(f'Loading {args.vols_fn}...')\n",
    "    # vols, res, pos = volume.read_volume(args.vols_fn, hdf_ds_name='volumes')\n",
    "    # vols = torch.tensor(vols, device='cuda')\n",
    "    # msks, *_ = volume.read_volume(args.vols_fn, hdf_ds_name='masks')\n",
    "    # if msks is not None:\n",
    "    #     msks = torch.as_tensor(msks, dtype=bool)\n",
    "    #####\n",
    "    #vols, res, pos, msks are already defined\n",
    "    ####\n",
    "    vols=vols.to(pca.mean_vol.device)\n",
    "\n",
    "    append_cnt = 0\n",
    "    pca_mse_values = torch.zeros(vols.shape[0], pca.component_count+3)\n",
    "    pca_msk_mse_values = torch.zeros(vols.shape[0], pca.component_count+3)\n",
    "    dir_stats = np.empty((vols.shape[0], pca.component_count + 3), dtype=object)\n",
    "    dvf_stats = np.empty((vols.shape[0], pca.component_count + 3), dtype=object)\n",
    "\n",
    "    measurement_names = ['Reference', 'Mean'] + \\\n",
    "                        [f\"#{j} PCs\" for j in range(1, pca.component_count + 1)] + \\\n",
    "                        [f'Parametrization', f\"Param. (#{relevant_cnt} PCs)\"]\n",
    "    measurement_list = []\n",
    "    reconstructed_vol_lst = []\n",
    "    for i in range(vols.shape[0]):\n",
    "        ref_vol = vols[i]\n",
    "        ref_dvf = pca.dvf(pca.vt[i, :]).cpu() #NOTE ref_dvf does not have batch dimension\n",
    "\n",
    "        if msks is not None:\n",
    "            ref_msk = msks[min(i, msks.shape[0] - 1)]\n",
    "        else:\n",
    "            ref_msk = seg_body(ref_vol.cpu().numpy(), air_threshold=air_threshold)\n",
    "        ref_msk_np = ref_msk if isinstance(ref_msk, np.ndarray) else ref_msk.cpu().numpy()\n",
    "        mvl = measure_voi_list(cfg.edge_measurements, ref_vol, res, pos)\n",
    "        measurements = [m['dst'] for m in mvl]\n",
    "        for j in range(pca.component_count + 1):\n",
    "            pca_vol = pca.vol(pca.vt[i, :j])\n",
    "            mvl = measure_voi_list(cfg.edge_measurements, pca_vol, res, pos)\n",
    "            measurements += [m['dst'] for m in mvl]\n",
    "            pca_mse_values[i, j] = mse(pca_vol, ref_vol).cpu()\n",
    "            pca_msk_mse_values[i, j] = msk_mse(ref_vol, pca_vol, ref_msk)\n",
    "\n",
    "            residual_dvf = (ref_dvf - pca.dvf(pca.vt[i, :j]).cpu()).millimeter(res)\n",
    "            dvf_stats[i, j] = dvf_statistics(residual_dvf, ref_msk, max_value=cfg.maximum_mag)\n",
    "            save_mag_max_intensity(os.path.join(dst_path, stats_path, f'dvf_max_magnitude_{i}_{j}.png'),\n",
    "                                f'Maximum Magnitude {measurement_names[j + 1]}', residual_dvf.magnitude(),\n",
    "                                res, cfg.maximum_mag)\n",
    "\n",
    "            if comp_dir:\n",
    "                dvf = residual_deformation(ref_vol.cpu(), pca_vol.cpu(), res, ref_msk=ref_msk_np, prefilter=args.prefilter, mode='cubic' if True==args.prefilter else 'bilinear').squeeze() #residual_deformation(ref_vol.cpu(), pca_vol.cpu(), res, ref_msk=ref_msk)\n",
    "                dir_stats[i, j] = dvf_statistics(dvf, ref_msk, max_value=cfg.maximum_mag)\n",
    "\n",
    "                mag = dvf.magnitude()\n",
    "                save_mag_max_intensity(os.path.join(dst_path, stats_path, f'dir_max_magnitude_{i}_{j}.png'),\n",
    "                                    f'Maximum Magnitude {measurement_names[j+1]}', mag, res, cfg.maximum_mag)\n",
    "\n",
    "\n",
    "        pca_vol = pca.vol(pca.vt[i, :])\n",
    "        #This is the reconstructed phase volume\n",
    "        reconstructed_vol_lst.append(pca_vol[None, ...].cpu().numpy())\n",
    "        vol_hat = pca.vol(vt_hat[i, :])\n",
    "        vol_hat_relevant = pca.vol(vt_hat[i, :relevant_cnt])\n",
    "\n",
    "        mvl = measure_voi_list(cfg.edge_measurements, vol_hat, res, pos)\n",
    "        measurements += [m['dst'] for m in mvl]\n",
    "\n",
    "        mvl = measure_voi_list(cfg.edge_measurements, vol_hat_relevant, res, pos)\n",
    "        measurements += [m['dst'] for m in mvl]\n",
    "\n",
    "        if len(measurements) > 0:\n",
    "            measurement_list += [measurements]\n",
    "\n",
    "        pca_mse_values[i, -2] = mse(vol_hat, ref_vol).cpu()\n",
    "        pca_mse_values[i, -1] = mse(vol_hat_relevant, ref_vol).cpu()\n",
    "\n",
    "        pca_msk_mse_values[i, -2] = msk_mse(ref_vol, vol_hat, ref_msk)\n",
    "        pca_msk_mse_values[i, -1] = msk_mse(ref_vol, vol_hat_relevant, ref_msk)\n",
    "\n",
    "        residual_dvf = (ref_dvf - pca.dvf(vt_hat[i, :]).cpu()).millimeter(res)\n",
    "        dvf_stats[i, -2] = dvf_statistics(residual_dvf, ref_msk, max_value=cfg.maximum_mag)\n",
    "        save_mag_max_intensity(os.path.join(dst_path, stats_path, f'dvf_max_magnitude_{i}_param.png'),\n",
    "                            f'Maximum Magnitude {measurement_names[-2]}', residual_dvf.magnitude(),\n",
    "                            res, cfg.maximum_mag)\n",
    "\n",
    "        residual_dvf = (ref_dvf - pca.dvf(vt_hat[i, :relevant_cnt]).cpu()).millimeter(res)\n",
    "        dvf_stats[i, -1] = dvf_statistics(residual_dvf, ref_msk, max_value=cfg.maximum_mag)\n",
    "        save_mag_max_intensity(os.path.join(dst_path, stats_path, f'dvf_max_magnitude_{i}_param_{relevant_cnt}.png'),\n",
    "                            f'Maximum Magnitude {measurement_names[-1]}', residual_dvf.magnitude(),\n",
    "                            res, cfg.maximum_mag)\n",
    "\n",
    "        if comp_dir:\n",
    "            dvf = residual_deformation(ref_vol.cpu(), vol_hat.cpu(), res, ref_msk=ref_msk_np, prefilter=args.prefilter, mode='cubic' if True==args.prefilter else 'bilinear').squeeze() #dvf = residual_deformation(ref_vol.cpu(), vol_hat.cpu(), res, ref_msk=ref_msk)\n",
    "            dir_stats[i, -2] = dvf_statistics(dvf, ref_msk, max_value=cfg.maximum_mag)\n",
    "            save_mag_max_intensity(os.path.join(dst_path, stats_path, f'dir_max_magnitude_{i}_param.png'),\n",
    "                                f'Maximum Magnitude {measurement_names[-2]}', dvf.magnitude(), res, cfg.maximum_mag)\n",
    "\n",
    "            dvf = residual_deformation(ref_vol.cpu(), vol_hat_relevant.cpu(), res, ref_msk=ref_msk_np, prefilter=args.prefilter, mode='cubic' if True==args.prefilter else 'bilinear').squeeze() #dvf = residual_deformation(ref_vol.cpu(), vol_hat_relevant.cpu(), res, ref_msk=ref_msk)\n",
    "            dir_stats[i, -1] = dvf_statistics(dvf, ref_msk, max_value=cfg.maximum_mag)\n",
    "\n",
    "            save_mag_max_intensity(os.path.join(dst_path, stats_path, f'dir_max_magnitude_{i}_param_{relevant_cnt}.png'),\n",
    "                                f'Maximum Magnitude {measurement_names[-1]}', dvf.magnitude(), res, cfg.maximum_mag)\n",
    "\n",
    "        save_ortho_views(f'{i}: Image', ref_vol, res, pos,\n",
    "                        dst_path=os.path.join(dst_path, 'pca_eval'), fn=f'src_{i}.png', views=cfg.views)\n",
    "\n",
    "        save_ortho_views(f'{i}: Model', pca_vol, res, pos,\n",
    "                        dst_path=os.path.join(dst_path, 'pca_eval'), fn=f'model_{i}.png', views=cfg.views)\n",
    "\n",
    "        save_ortho_views(f'{i}: Residual (Image-Model)', ref_vol - pca_vol, res, pos,\n",
    "                        dst_path=os.path.join(dst_path, 'pca_eval'), fn=f'diff_{i}.png', views=cfg.views)\n",
    "\n",
    "        save_ortho_views(f'{i}: Param Model', vol_hat, res, pos,\n",
    "                        dst_path=os.path.join(dst_path, 'pca_eval'), fn=f'param_model_{i}.png', views=cfg.views)\n",
    "\n",
    "        save_ortho_views(f'{i}: Residual (Image-Param)', ref_vol - vol_hat, res, pos,\n",
    "                        dst_path=os.path.join(dst_path, 'pca_eval'), fn=f'param_diff_{i}.png', views=cfg.views)\n",
    "\n",
    "        save_ortho_views(f'{i}: Residual (Model-Param)', pca_vol - vol_hat, res, pos,\n",
    "                        dst_path=os.path.join(dst_path, 'pca_eval'), fn=f'model_param_diff_{i}.png', views=cfg.views)\n",
    "\n",
    "    save_all_mse_plots(pca_mse_values, measurement_names[1:], dst_path, 'full', 'Residual MSE', 4550)\n",
    "    save_all_mse_plots(pca_msk_mse_values, measurement_names[1:], dst_path, 'msk', 'Masked Residual MSE', 304020)\n",
    "\n",
    "    dvf_stats = transform_stats(dvf_stats)\n",
    "    save_all_roc_curves(dvf_stats, measurement_names, os.path.join(dst_path, stats_path),\n",
    "                        'Residual DVF Magnitude ROC', 'dvf', maximum_mag=cfg.maximum_mag)\n",
    "\n",
    "    save_cum_roc_curves(dvf_stats, measurement_names, os.path.join(dst_path, stats_path),\n",
    "                        'Residual DVF Magnitude ROC', 'total_dvf', maximum_mag=cfg.maximum_mag)\n",
    "\n",
    "    plot_stats(dvf_stats['mag_max'],\n",
    "            'Residual DVF - Magnitude Maximum', measurement_names[1:],\n",
    "            fn=os.path.join(dst_path, stats_path, 'dvf_mag_max.png'))\n",
    "\n",
    "    plot_stats(dvf_stats['mag_mean'],\n",
    "            'Residual DVF - Magnitude Mean', measurement_names[1:],\n",
    "            fn=os.path.join(dst_path, stats_path, 'dvf_mag_mean.png'))\n",
    "\n",
    "    plot_stats(dvf_stats['mag_std'],\n",
    "            'Residual DVF - Magnitude STD', measurement_names[1:],\n",
    "            fn=os.path.join(dst_path, stats_path, 'dvf_mag_std.png'))\n",
    "\n",
    "\n",
    "    if comp_dir:\n",
    "        dir_stats = transform_stats(dir_stats)\n",
    "        save_all_roc_curves(dir_stats, measurement_names, os.path.join(dst_path, stats_path),\n",
    "                            'Residual DIR Magnitude ROC', 'dir', maximum_mag=cfg.maximum_mag)\n",
    "        save_cum_roc_curves(dir_stats, measurement_names, os.path.join(dst_path, stats_path),\n",
    "                            'Residual DIR Magnitude ROC', 'total_dir', maximum_mag=cfg.maximum_mag)\n",
    "\n",
    "        plot_stats(dir_stats['mag_max'],\n",
    "                'Deformable Image Registration - Magnitude Maximum', measurement_names[1:],\n",
    "                fn=os.path.join(dst_path, stats_path, 'dir_mag_max.png'))\n",
    "\n",
    "        plot_stats(dir_stats['mag_mean'],\n",
    "                'Deformable Image Registration - Magnitude Mean', measurement_names[1:],\n",
    "                fn=os.path.join(dst_path, stats_path, 'dir_mag_mean.png'))\n",
    "\n",
    "        plot_stats(dir_stats['mag_std'],\n",
    "                'Deformable Image Registration - Magnitude STD', measurement_names[1:],\n",
    "                fn=os.path.join(dst_path, stats_path, 'dir_mag_std.png'))\n",
    "\n",
    "    with open(os.path.join(dst_path, 'pca_mse_values.csv'), 'w', newline='') as csvfile:\n",
    "        wrt = csv.writer(csvfile, delimiter=',')\n",
    "        wrt.writerow([f'{j} Components' for j in range(pca.component_count)] +\n",
    "                    [f'Parametrization {\"amplitude\" if args.amplitude_gated else \"phase\"} gated',\n",
    "                    f'Reduced ({relevant_cnt}) parametrization {\"amplitude\" if args.amplitude_gated else \"phase\"} gated',\n",
    "                    'Masked'])\n",
    "\n",
    "        for pmse in pca_mse_values:\n",
    "            wrt.writerow(pmse.tolist() + ['False'])\n",
    "        for pmse in pca_msk_mse_values:\n",
    "            wrt.writerow(pmse.tolist() + ['True'])\n",
    "\n",
    "    em_cnt = len(cfg.edge_measurements)\n",
    "    if em_cnt > 0:\n",
    "        measurement_list = np.array(measurement_list)\n",
    "        measurement_list = measurement_list.reshape((measurement_list.shape[0], -1, em_cnt))\n",
    "\n",
    "        for i in range(em_cnt):\n",
    "            # ['Reference', 'Mean', '1 pc', '2 pc', '3 pc', '4 pc', '5 pc', '6 pc', '7 pc', 'Parameterized', 'Relevant']\n",
    "            save_measurement_plot(os.path.join(dst_path, f'profile_all_{i}.png'),\n",
    "                                measurement_names, measurement_list[..., i], args.amplitude_gated)\n",
    "\n",
    "            col_indices = [0, 2, 3, -4, -2, -1]\n",
    "            save_measurement_plot(os.path.join(dst_path, f'profile_cmp_{i}.png'),\n",
    "                                measurement_names, measurement_list[..., i], args.amplitude_gated, col_indices=col_indices)\n",
    "\n",
    "            col_indices = [0, 2, 3, -4]\n",
    "            save_measurement_plot(os.path.join(dst_path, f'profile_pca_{i}.png'),\n",
    "                                measurement_names, measurement_list[..., i], args.amplitude_gated, col_indices=col_indices)\n",
    "\n",
    "            col_indices = [0, -2, -1]\n",
    "            save_measurement_plot(os.path.join(dst_path, f'profile_param_{i}.png'),\n",
    "                                measurement_names, measurement_list[..., i], args.amplitude_gated, col_indices=col_indices)\n",
    "\n",
    "        with open(os.path.join(dst_path, 'measurements.csv'), 'w', newline='') as csvfile:\n",
    "            wrt = csv.writer(csvfile, delimiter=',')\n",
    "            for i in range(em_cnt):\n",
    "                wrt.writerow(measurement_names)\n",
    "                for m in measurement_list[..., i]:\n",
    "                    wrt.writerow(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Memory clean up\n",
    "del vols\n",
    "del pca\n",
    "del dvfs\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(f'<<<<<<<<<< Finished reconstruction vols and  generation for {behaviourPrefixedConfigKey}_{patientMRN} >>>>>>>>>>>>>>>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clone2MMIPython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
